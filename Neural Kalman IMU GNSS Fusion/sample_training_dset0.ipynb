{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geographic-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "from math import atan2, pi, sqrt, cos, sin, floor\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2)  \n",
    "from tensorflow.keras.layers import Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import uniform\n",
    "from keras_flops import get_flops\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from dataset0.data_utils_0_revised import *\n",
    "from traj_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32835c2",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preceding-parker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of log files being imported:  ['Log1, 100.csv', 'Log2, 100.csv', 'Log3, 100.csv', 'Log4, 100.csv', 'Log6, 100.csv', 'Log7, 100.csv', 'Log9, 100.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of log files being imported:  ['Log5, 100.csv', 'Log8, 100.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "stride = 20\n",
    "\n",
    "f = 'dataset0/'\n",
    "X_train,Y_Pos_train, Physics_Vec_train, x_vel_train, y_vel_train, x0_list_train, y0_list_train, size_of_each_train = import_agrobot_dataset_p1(dataset_folder=f, type_flag=1, window_size=window_size, stride=stride)\n",
    "P = np.repeat(Physics_Vec_train,window_size).reshape((Physics_Vec_train.shape[0],window_size,1))\n",
    "X_train = np.concatenate((X_train,P),axis=2)\n",
    "\n",
    "X_test,Y_Pos_test, Physics_Vec_test, x_vel_test, y_vel_test, x0_list_test, y0_list_test, size_of_each_test= import_agrobot_dataset_p1(type_flag = 2, dataset_folder=f,window_size=window_size, stride=stride)\n",
    "P_test = np.repeat(Physics_Vec_test,window_size).reshape((Physics_Vec_test.shape[0],window_size,1))\n",
    "X_test = np.concatenate((X_test,P_test),axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f386a6",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tcn (TCN)                       (None, 32)           78688       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 32, 1)        0           tcn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 16, 1)        0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16)           0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pre (Dense)                     (None, 32)           544         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "velx (Dense)                    (None, 1)            33          pre[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "vely (Dense)                    (None, 1)            33          pre[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 79,298\n",
      "Trainable params: 79,298\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_filters = 32\n",
    "kernel_size = 5\n",
    "dilations = [1,2,4,8,16,32,64,128]\n",
    "dropout_rate = 0.0\n",
    "use_skip_connections = True\n",
    "\n",
    "batch_size, timesteps, input_dim = 256, window_size, X_train.shape[2]\n",
    "i = Input(shape=(timesteps, input_dim))\n",
    "\n",
    "m = TCN(nb_filters=nb_filters,kernel_size=kernel_size,dilations=dilations,dropout_rate=dropout_rate,\n",
    "            use_skip_connections=use_skip_connections)(i)  \n",
    "\n",
    "m = tf.reshape(m, [-1, nb_filters, 1])\n",
    "m = MaxPooling1D(pool_size=(2))(m)\n",
    "m = Flatten()(m)\n",
    "m = Dense(32, activation='linear', name='pre')(m)\n",
    "output1 = Dense(1, activation='linear', name='velx')(m)\n",
    "output2 = Dense(1, activation='linear', name='vely')(m)\n",
    "model = Model(inputs=[i], outputs=[output1, output2])\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(loss={'velx': 'mse','vely':'mse'},optimizer=opt)  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ranging-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "352/352 [==============================] - 68s 189ms/step - loss: 0.5757 - velx_loss: 0.3474 - vely_loss: 0.2282\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.57566, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 2/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0591 - velx_loss: 0.0341 - vely_loss: 0.0250\n",
      "\n",
      "Epoch 00002: loss improved from 0.57566 to 0.05912, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 3/3000\n",
      "352/352 [==============================] - 66s 188ms/step - loss: 0.0350 - velx_loss: 0.0198 - vely_loss: 0.0152\n",
      "\n",
      "Epoch 00003: loss improved from 0.05912 to 0.03499, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 4/3000\n",
      "352/352 [==============================] - 66s 188ms/step - loss: 0.0268 - velx_loss: 0.0148 - vely_loss: 0.0119\n",
      "\n",
      "Epoch 00004: loss improved from 0.03499 to 0.02677, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 5/3000\n",
      "352/352 [==============================] - 65s 186ms/step - loss: 0.0232 - velx_loss: 0.0127 - vely_loss: 0.0106\n",
      "\n",
      "Epoch 00005: loss improved from 0.02677 to 0.02325, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 6/3000\n",
      "352/352 [==============================] - 67s 189ms/step - loss: 0.0209 - velx_loss: 0.0112 - vely_loss: 0.0097\n",
      "\n",
      "Epoch 00006: loss improved from 0.02325 to 0.02088, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 7/3000\n",
      "352/352 [==============================] - 66s 186ms/step - loss: 0.0195 - velx_loss: 0.0103 - vely_loss: 0.0092\n",
      "\n",
      "Epoch 00007: loss improved from 0.02088 to 0.01948, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 8/3000\n",
      "352/352 [==============================] - 65s 184ms/step - loss: 0.0185 - velx_loss: 0.0097 - vely_loss: 0.0089\n",
      "\n",
      "Epoch 00008: loss improved from 0.01948 to 0.01854, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 9/3000\n",
      "352/352 [==============================] - 65s 185ms/step - loss: 0.0180 - velx_loss: 0.0094 - vely_loss: 0.0087\n",
      "\n",
      "Epoch 00009: loss improved from 0.01854 to 0.01805, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 10/3000\n",
      "352/352 [==============================] - 65s 184ms/step - loss: 0.0177 - velx_loss: 0.0091 - vely_loss: 0.0086\n",
      "\n",
      "Epoch 00010: loss improved from 0.01805 to 0.01766, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 11/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0173 - velx_loss: 0.0088 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00011: loss improved from 0.01766 to 0.01728, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 12/3000\n",
      "352/352 [==============================] - 68s 192ms/step - loss: 0.0170 - velx_loss: 0.0086 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00012: loss improved from 0.01728 to 0.01704, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 13/3000\n",
      "352/352 [==============================] - 68s 193ms/step - loss: 0.0169 - velx_loss: 0.0084 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00013: loss improved from 0.01704 to 0.01685, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 14/3000\n",
      "352/352 [==============================] - 67s 190ms/step - loss: 0.0167 - velx_loss: 0.0083 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00014: loss improved from 0.01685 to 0.01673, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 15/3000\n",
      "352/352 [==============================] - 67s 191ms/step - loss: 0.0168 - velx_loss: 0.0083 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.01673\n",
      "Epoch 16/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0168 - velx_loss: 0.0083 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.01673\n",
      "Epoch 17/3000\n",
      "352/352 [==============================] - 66s 189ms/step - loss: 0.0168 - velx_loss: 0.0083 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.01673\n",
      "Epoch 18/3000\n",
      "352/352 [==============================] - 66s 188ms/step - loss: 0.0168 - velx_loss: 0.0082 - vely_loss: 0.0086\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.01673\n",
      "Epoch 19/3000\n",
      "352/352 [==============================] - 67s 190ms/step - loss: 0.0166 - velx_loss: 0.0082 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00019: loss improved from 0.01673 to 0.01661, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 20/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0166 - velx_loss: 0.0082 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.01661\n",
      "Epoch 21/3000\n",
      "352/352 [==============================] - 65s 185ms/step - loss: 0.0166 - velx_loss: 0.0082 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.01661\n",
      "Epoch 22/3000\n",
      "352/352 [==============================] - 53s 150ms/step - loss: 0.0166 - velx_loss: 0.0081 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.01661\n",
      "Epoch 23/3000\n",
      "352/352 [==============================] - 51s 144ms/step - loss: 0.0166 - velx_loss: 0.0082 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00023: loss improved from 0.01661 to 0.01660, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 24/3000\n",
      "352/352 [==============================] - 49s 139ms/step - loss: 0.0165 - velx_loss: 0.0081 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00024: loss improved from 0.01660 to 0.01650, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 25/3000\n",
      "352/352 [==============================] - 51s 144ms/step - loss: 0.0165 - velx_loss: 0.0081 - vely_loss: 0.0084\n",
      "\n",
      "Epoch 00025: loss improved from 0.01650 to 0.01648, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 26/3000\n",
      "352/352 [==============================] - 46s 129ms/step - loss: 0.0166 - velx_loss: 0.0081 - vely_loss: 0.0085\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.01648\n",
      "Epoch 27/3000\n",
      "352/352 [==============================] - 52s 147ms/step - loss: 0.0164 - velx_loss: 0.0081 - vely_loss: 0.0083\n",
      "\n",
      "Epoch 00027: loss improved from 0.01648 to 0.01643, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 28/3000\n",
      "352/352 [==============================] - 51s 144ms/step - loss: 0.0164 - velx_loss: 0.0081 - vely_loss: 0.0083\n",
      "\n",
      "Epoch 00028: loss improved from 0.01643 to 0.01642, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 29/3000\n",
      "352/352 [==============================] - 46s 129ms/step - loss: 0.0164 - velx_loss: 0.0081 - vely_loss: 0.0083\n",
      "\n",
      "Epoch 00029: loss improved from 0.01642 to 0.01636, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 30/3000\n",
      "352/352 [==============================] - 47s 133ms/step - loss: 0.0163 - velx_loss: 0.0081 - vely_loss: 0.0083\n",
      "\n",
      "Epoch 00030: loss improved from 0.01636 to 0.01634, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 31/3000\n",
      "352/352 [==============================] - 54s 154ms/step - loss: 0.0163 - velx_loss: 0.0081 - vely_loss: 0.0082\n",
      "\n",
      "Epoch 00031: loss improved from 0.01634 to 0.01626, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 32/3000\n",
      "352/352 [==============================] - 53s 151ms/step - loss: 0.0161 - velx_loss: 0.0080 - vely_loss: 0.0081\n",
      "\n",
      "Epoch 00032: loss improved from 0.01626 to 0.01611, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 33/3000\n",
      "352/352 [==============================] - 50s 141ms/step - loss: 0.0159 - velx_loss: 0.0080 - vely_loss: 0.0079\n",
      "\n",
      "Epoch 00033: loss improved from 0.01611 to 0.01594, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 34/3000\n",
      "352/352 [==============================] - 62s 177ms/step - loss: 0.0159 - velx_loss: 0.0080 - vely_loss: 0.0078\n",
      "\n",
      "Epoch 00034: loss improved from 0.01594 to 0.01587, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 35/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0158 - velx_loss: 0.0080 - vely_loss: 0.0078\n",
      "\n",
      "Epoch 00035: loss improved from 0.01587 to 0.01580, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 36/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0156 - velx_loss: 0.0080 - vely_loss: 0.0076\n",
      "\n",
      "Epoch 00036: loss improved from 0.01580 to 0.01562, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 37/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0155 - velx_loss: 0.0080 - vely_loss: 0.0075\n",
      "\n",
      "Epoch 00037: loss improved from 0.01562 to 0.01547, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 38/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0152 - velx_loss: 0.0079 - vely_loss: 0.0073\n",
      "\n",
      "Epoch 00038: loss improved from 0.01547 to 0.01522, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 39/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0152 - velx_loss: 0.0079 - vely_loss: 0.0072\n",
      "\n",
      "Epoch 00039: loss improved from 0.01522 to 0.01516, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 40/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0150 - velx_loss: 0.0079 - vely_loss: 0.0071\n",
      "\n",
      "Epoch 00040: loss improved from 0.01516 to 0.01496, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 41/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0148 - velx_loss: 0.0079 - vely_loss: 0.0070\n",
      "\n",
      "Epoch 00041: loss improved from 0.01496 to 0.01484, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 42/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0146 - velx_loss: 0.0078 - vely_loss: 0.0069\n",
      "\n",
      "Epoch 00042: loss improved from 0.01484 to 0.01462, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 43/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0144 - velx_loss: 0.0077 - vely_loss: 0.0067\n",
      "\n",
      "Epoch 00043: loss improved from 0.01462 to 0.01441, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 44/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0143 - velx_loss: 0.0077 - vely_loss: 0.0066\n",
      "\n",
      "Epoch 00044: loss improved from 0.01441 to 0.01426, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 45/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0141 - velx_loss: 0.0076 - vely_loss: 0.0065\n",
      "\n",
      "Epoch 00045: loss improved from 0.01426 to 0.01412, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 46/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0138 - velx_loss: 0.0075 - vely_loss: 0.0063\n",
      "\n",
      "Epoch 00046: loss improved from 0.01412 to 0.01382, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 47/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0136 - velx_loss: 0.0074 - vely_loss: 0.0062\n",
      "\n",
      "Epoch 00047: loss improved from 0.01382 to 0.01365, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 48/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0135 - velx_loss: 0.0073 - vely_loss: 0.0061\n",
      "\n",
      "Epoch 00048: loss improved from 0.01365 to 0.01349, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 49/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0132 - velx_loss: 0.0072 - vely_loss: 0.0060\n",
      "\n",
      "Epoch 00049: loss improved from 0.01349 to 0.01323, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 50/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0131 - velx_loss: 0.0071 - vely_loss: 0.0059\n",
      "\n",
      "Epoch 00050: loss improved from 0.01323 to 0.01307, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 51/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0128 - velx_loss: 0.0070 - vely_loss: 0.0058\n",
      "\n",
      "Epoch 00051: loss improved from 0.01307 to 0.01281, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 52/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0125 - velx_loss: 0.0069 - vely_loss: 0.0056\n",
      "\n",
      "Epoch 00052: loss improved from 0.01281 to 0.01251, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 53/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0124 - velx_loss: 0.0068 - vely_loss: 0.0056\n",
      "\n",
      "Epoch 00053: loss improved from 0.01251 to 0.01239, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 54/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0123 - velx_loss: 0.0067 - vely_loss: 0.0055\n",
      "\n",
      "Epoch 00054: loss improved from 0.01239 to 0.01225, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 55/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0120 - velx_loss: 0.0066 - vely_loss: 0.0054\n",
      "\n",
      "Epoch 00055: loss improved from 0.01225 to 0.01195, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 56/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0117 - velx_loss: 0.0064 - vely_loss: 0.0053\n",
      "\n",
      "Epoch 00056: loss improved from 0.01195 to 0.01168, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 57/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0114 - velx_loss: 0.0062 - vely_loss: 0.0052\n",
      "\n",
      "Epoch 00057: loss improved from 0.01168 to 0.01138, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 58/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0112 - velx_loss: 0.0061 - vely_loss: 0.0051\n",
      "\n",
      "Epoch 00058: loss improved from 0.01138 to 0.01124, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 59/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0109 - velx_loss: 0.0060 - vely_loss: 0.0050\n",
      "\n",
      "Epoch 00059: loss improved from 0.01124 to 0.01093, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 60/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0108 - velx_loss: 0.0058 - vely_loss: 0.0050\n",
      "\n",
      "Epoch 00060: loss improved from 0.01093 to 0.01083, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 61/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0105 - velx_loss: 0.0057 - vely_loss: 0.0048\n",
      "\n",
      "Epoch 00061: loss improved from 0.01083 to 0.01048, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 62/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0104 - velx_loss: 0.0056 - vely_loss: 0.0048\n",
      "\n",
      "Epoch 00062: loss improved from 0.01048 to 0.01040, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 63/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0100 - velx_loss: 0.0054 - vely_loss: 0.0046\n",
      "\n",
      "Epoch 00063: loss improved from 0.01040 to 0.00996, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 64/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0098 - velx_loss: 0.0052 - vely_loss: 0.0045\n",
      "\n",
      "Epoch 00064: loss improved from 0.00996 to 0.00979, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 65/3000\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.0095 - velx_loss: 0.0051 - vely_loss: 0.0044\n",
      "\n",
      "Epoch 00065: loss improved from 0.00979 to 0.00953, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 66/3000\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 0.0095 - velx_loss: 0.0050 - vely_loss: 0.0045\n",
      "\n",
      "Epoch 00066: loss improved from 0.00953 to 0.00951, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 67/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0092 - velx_loss: 0.0048 - vely_loss: 0.0043\n",
      "\n",
      "Epoch 00067: loss improved from 0.00951 to 0.00917, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 68/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0090 - velx_loss: 0.0047 - vely_loss: 0.0042\n",
      "\n",
      "Epoch 00068: loss improved from 0.00917 to 0.00895, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 69/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0088 - velx_loss: 0.0046 - vely_loss: 0.0042\n",
      "\n",
      "Epoch 00069: loss improved from 0.00895 to 0.00875, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 70/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0087 - velx_loss: 0.0045 - vely_loss: 0.0041\n",
      "\n",
      "Epoch 00070: loss improved from 0.00875 to 0.00869, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 71/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0084 - velx_loss: 0.0044 - vely_loss: 0.0041\n",
      "\n",
      "Epoch 00071: loss improved from 0.00869 to 0.00841, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 72/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0083 - velx_loss: 0.0043 - vely_loss: 0.0040\n",
      "\n",
      "Epoch 00072: loss improved from 0.00841 to 0.00827, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 73/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0081 - velx_loss: 0.0042 - vely_loss: 0.0039\n",
      "\n",
      "Epoch 00073: loss improved from 0.00827 to 0.00810, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 74/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0079 - velx_loss: 0.0041 - vely_loss: 0.0038\n",
      "\n",
      "Epoch 00074: loss improved from 0.00810 to 0.00787, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 75/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0078 - velx_loss: 0.0040 - vely_loss: 0.0038\n",
      "\n",
      "Epoch 00075: loss improved from 0.00787 to 0.00777, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 76/3000\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.0077 - velx_loss: 0.0039 - vely_loss: 0.0037\n",
      "\n",
      "Epoch 00076: loss improved from 0.00777 to 0.00767, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 77/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0074 - velx_loss: 0.0038 - vely_loss: 0.0037\n",
      "\n",
      "Epoch 00077: loss improved from 0.00767 to 0.00744, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 78/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0073 - velx_loss: 0.0037 - vely_loss: 0.0036\n",
      "\n",
      "Epoch 00078: loss improved from 0.00744 to 0.00725, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 79/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0071 - velx_loss: 0.0036 - vely_loss: 0.0035\n",
      "\n",
      "Epoch 00079: loss improved from 0.00725 to 0.00715, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 80/3000\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.0070 - velx_loss: 0.0035 - vely_loss: 0.0035\n",
      "\n",
      "Epoch 00080: loss improved from 0.00715 to 0.00699, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 81/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0069 - velx_loss: 0.0035 - vely_loss: 0.0035\n",
      "\n",
      "Epoch 00081: loss improved from 0.00699 to 0.00695, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 82/3000\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.0069 - velx_loss: 0.0034 - vely_loss: 0.0034\n",
      "\n",
      "Epoch 00082: loss improved from 0.00695 to 0.00685, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 83/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0068 - velx_loss: 0.0034 - vely_loss: 0.0034\n",
      "\n",
      "Epoch 00083: loss improved from 0.00685 to 0.00675, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 84/3000\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.0066 - velx_loss: 0.0033 - vely_loss: 0.0033\n",
      "\n",
      "Epoch 00084: loss improved from 0.00675 to 0.00660, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 85/3000\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.0064 - velx_loss: 0.0032 - vely_loss: 0.0032\n",
      "\n",
      "Epoch 00085: loss improved from 0.00660 to 0.00640, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 86/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0063 - velx_loss: 0.0031 - vely_loss: 0.0032\n",
      "\n",
      "Epoch 00086: loss improved from 0.00640 to 0.00635, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 87/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0063 - velx_loss: 0.0031 - vely_loss: 0.0032\n",
      "\n",
      "Epoch 00087: loss improved from 0.00635 to 0.00631, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 88/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0061 - velx_loss: 0.0030 - vely_loss: 0.0031\n",
      "\n",
      "Epoch 00088: loss improved from 0.00631 to 0.00614, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 89/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0061 - velx_loss: 0.0030 - vely_loss: 0.0031\n",
      "\n",
      "Epoch 00089: loss improved from 0.00614 to 0.00606, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 90/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0060 - velx_loss: 0.0030 - vely_loss: 0.0031\n",
      "\n",
      "Epoch 00090: loss improved from 0.00606 to 0.00604, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 91/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0059 - velx_loss: 0.0029 - vely_loss: 0.0030\n",
      "\n",
      "Epoch 00091: loss improved from 0.00604 to 0.00591, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 92/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0058 - velx_loss: 0.0028 - vely_loss: 0.0029\n",
      "\n",
      "Epoch 00092: loss improved from 0.00591 to 0.00579, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 93/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0057 - velx_loss: 0.0028 - vely_loss: 0.0029\n",
      "\n",
      "Epoch 00093: loss improved from 0.00579 to 0.00571, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 94/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0055 - velx_loss: 0.0027 - vely_loss: 0.0028\n",
      "\n",
      "Epoch 00094: loss improved from 0.00571 to 0.00554, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 95/3000\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.0056 - velx_loss: 0.0027 - vely_loss: 0.0029\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.00554\n",
      "Epoch 96/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0054 - velx_loss: 0.0026 - vely_loss: 0.0028\n",
      "\n",
      "Epoch 00096: loss improved from 0.00554 to 0.00539, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 97/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0054 - velx_loss: 0.0027 - vely_loss: 0.0028\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.00539\n",
      "Epoch 98/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0053 - velx_loss: 0.0026 - vely_loss: 0.0028\n",
      "\n",
      "Epoch 00098: loss improved from 0.00539 to 0.00534, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 99/3000\n",
      "352/352 [==============================] - 91s 260ms/step - loss: 0.0052 - velx_loss: 0.0025 - vely_loss: 0.0027\n",
      "\n",
      "Epoch 00099: loss improved from 0.00534 to 0.00520, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 100/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0053 - velx_loss: 0.0026 - vely_loss: 0.0027\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.00520\n",
      "Epoch 101/3000\n",
      "352/352 [==============================] - 91s 260ms/step - loss: 0.0051 - velx_loss: 0.0025 - vely_loss: 0.0026\n",
      "\n",
      "Epoch 00101: loss improved from 0.00520 to 0.00511, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 102/3000\n",
      "352/352 [==============================] - 91s 260ms/step - loss: 0.0051 - velx_loss: 0.0025 - vely_loss: 0.0026\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.00511\n",
      "Epoch 103/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0052 - velx_loss: 0.0025 - vely_loss: 0.0026\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.00511\n",
      "Epoch 104/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0049 - velx_loss: 0.0024 - vely_loss: 0.0025\n",
      "\n",
      "Epoch 00104: loss improved from 0.00511 to 0.00494, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 105/3000\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.0050 - velx_loss: 0.0024 - vely_loss: 0.0026\n",
      "\n",
      "Epoch 00105: loss did not improve from 0.00494\n",
      "Epoch 106/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0050 - velx_loss: 0.0024 - vely_loss: 0.0026\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.00494\n",
      "Epoch 107/3000\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.0048 - velx_loss: 0.0024 - vely_loss: 0.0025\n",
      "\n",
      "Epoch 00107: loss improved from 0.00494 to 0.00484, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 108/3000\n",
      "352/352 [==============================] - 92s 263ms/step - loss: 0.0048 - velx_loss: 0.0023 - vely_loss: 0.0025\n",
      "\n",
      "Epoch 00108: loss improved from 0.00484 to 0.00477, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 109/3000\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.0048 - velx_loss: 0.0023 - vely_loss: 0.0025\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.00477\n",
      "Epoch 110/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0047 - velx_loss: 0.0023 - vely_loss: 0.0024\n",
      "\n",
      "Epoch 00110: loss improved from 0.00477 to 0.00470, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 111/3000\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 0.0047 - velx_loss: 0.0023 - vely_loss: 0.0024\n",
      "\n",
      "Epoch 00111: loss improved from 0.00470 to 0.00468, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 112/3000\n",
      "352/352 [==============================] - 93s 263ms/step - loss: 0.0045 - velx_loss: 0.0022 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00112: loss improved from 0.00468 to 0.00450, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 113/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0046 - velx_loss: 0.0022 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.00450\n",
      "Epoch 114/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0045 - velx_loss: 0.0022 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00114: loss did not improve from 0.00450\n",
      "Epoch 115/3000\n",
      "352/352 [==============================] - 93s 263ms/step - loss: 0.0046 - velx_loss: 0.0023 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.00450\n",
      "Epoch 116/3000\n",
      "352/352 [==============================] - 92s 261ms/step - loss: 0.0046 - velx_loss: 0.0022 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00116: loss did not improve from 0.00450\n",
      "Epoch 117/3000\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 0.0044 - velx_loss: 0.0021 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00117: loss improved from 0.00450 to 0.00438, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 118/3000\n",
      "352/352 [==============================] - 93s 263ms/step - loss: 0.0044 - velx_loss: 0.0022 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00118: loss did not improve from 0.00438\n",
      "Epoch 119/3000\n",
      "352/352 [==============================] - 93s 264ms/step - loss: 0.0043 - velx_loss: 0.0021 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00119: loss improved from 0.00438 to 0.00433, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 120/3000\n",
      "352/352 [==============================] - 94s 267ms/step - loss: 0.0044 - velx_loss: 0.0021 - vely_loss: 0.0023\n",
      "\n",
      "Epoch 00120: loss did not improve from 0.00433\n",
      "Epoch 121/3000\n",
      "352/352 [==============================] - 94s 266ms/step - loss: 0.0043 - velx_loss: 0.0021 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00121: loss improved from 0.00433 to 0.00432, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 122/3000\n",
      "352/352 [==============================] - 93s 266ms/step - loss: 0.0042 - velx_loss: 0.0020 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00122: loss improved from 0.00432 to 0.00417, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 123/3000\n",
      "352/352 [==============================] - 93s 263ms/step - loss: 0.0042 - velx_loss: 0.0020 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.00417\n",
      "Epoch 124/3000\n",
      "352/352 [==============================] - 93s 264ms/step - loss: 0.0042 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00124: loss improved from 0.00417 to 0.00416, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 125/3000\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 0.0043 - velx_loss: 0.0021 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00125: loss did not improve from 0.00416\n",
      "Epoch 126/3000\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 0.0042 - velx_loss: 0.0020 - vely_loss: 0.0022\n",
      "\n",
      "Epoch 00126: loss did not improve from 0.00416\n",
      "Epoch 127/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0041 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00127: loss improved from 0.00416 to 0.00409, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 128/3000\n",
      "352/352 [==============================] - 66s 189ms/step - loss: 0.0040 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00128: loss improved from 0.00409 to 0.00397, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 129/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0042 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00129: loss did not improve from 0.00397\n",
      "Epoch 130/3000\n",
      "352/352 [==============================] - 66s 188ms/step - loss: 0.0041 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00130: loss did not improve from 0.00397\n",
      "Epoch 131/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0040 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00131: loss did not improve from 0.00397\n",
      "Epoch 132/3000\n",
      "352/352 [==============================] - 66s 187ms/step - loss: 0.0041 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00132: loss did not improve from 0.00397\n",
      "Epoch 133/3000\n",
      "352/352 [==============================] - 65s 184ms/step - loss: 0.0041 - velx_loss: 0.0020 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00133: loss did not improve from 0.00397\n",
      "Epoch 134/3000\n",
      "352/352 [==============================] - 64s 182ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00134: loss improved from 0.00397 to 0.00386, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 135/3000\n",
      "352/352 [==============================] - 65s 184ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00135: loss did not improve from 0.00386\n",
      "Epoch 136/3000\n",
      "352/352 [==============================] - 65s 183ms/step - loss: 0.0040 - velx_loss: 0.0019 - vely_loss: 0.0021\n",
      "\n",
      "Epoch 00136: loss did not improve from 0.00386\n",
      "Epoch 137/3000\n",
      "352/352 [==============================] - 65s 185ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00137: loss did not improve from 0.00386\n",
      "Epoch 138/3000\n",
      "352/352 [==============================] - 65s 184ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00138: loss did not improve from 0.00386\n",
      "Epoch 139/3000\n",
      "352/352 [==============================] - 65s 185ms/step - loss: 0.0038 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00139: loss improved from 0.00386 to 0.00384, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 140/3000\n",
      "352/352 [==============================] - 66s 186ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.00384\n",
      "Epoch 141/3000\n",
      "352/352 [==============================] - 65s 186ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00141: loss did not improve from 0.00384\n",
      "Epoch 142/3000\n",
      "352/352 [==============================] - 65s 185ms/step - loss: 0.0038 - velx_loss: 0.0019 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00142: loss improved from 0.00384 to 0.00381, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 143/3000\n",
      "352/352 [==============================] - 65s 186ms/step - loss: 0.0038 - velx_loss: 0.0019 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00143: loss improved from 0.00381 to 0.00380, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 144/3000\n",
      "352/352 [==============================] - 53s 152ms/step - loss: 0.0037 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00144: loss improved from 0.00380 to 0.00372, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 145/3000\n",
      "352/352 [==============================] - 52s 147ms/step - loss: 0.0037 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.00372\n",
      "Epoch 146/3000\n",
      "352/352 [==============================] - 50s 142ms/step - loss: 0.0036 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00146: loss improved from 0.00372 to 0.00364, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 147/3000\n",
      "352/352 [==============================] - 50s 143ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00147: loss improved from 0.00364 to 0.00355, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 148/3000\n",
      "352/352 [==============================] - 55s 156ms/step - loss: 0.0037 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.00355\n",
      "Epoch 149/3000\n",
      "352/352 [==============================] - 52s 147ms/step - loss: 0.0037 - velx_loss: 0.0019 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.00355\n",
      "Epoch 150/3000\n",
      "352/352 [==============================] - 43s 123ms/step - loss: 0.0037 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.00355\n",
      "Epoch 151/3000\n",
      "352/352 [==============================] - 50s 141ms/step - loss: 0.0039 - velx_loss: 0.0019 - vely_loss: 0.0020\n",
      "\n",
      "Epoch 00151: loss did not improve from 0.00355\n",
      "Epoch 152/3000\n",
      "352/352 [==============================] - 56s 160ms/step - loss: 0.0036 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00152: loss did not improve from 0.00355\n",
      "Epoch 153/3000\n",
      "352/352 [==============================] - 65s 186ms/step - loss: 0.0036 - velx_loss: 0.0018 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00153: loss did not improve from 0.00355\n",
      "Epoch 154/3000\n",
      "352/352 [==============================] - 80s 228ms/step - loss: 0.0036 - velx_loss: 0.0018 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00154: loss did not improve from 0.00355\n",
      "Epoch 155/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0036 - velx_loss: 0.0018 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00155: loss did not improve from 0.00355\n",
      "Epoch 156/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0036 - velx_loss: 0.0018 - vely_loss: 0.0019\n",
      "\n",
      "Epoch 00156: loss did not improve from 0.00355\n",
      "Epoch 157/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00157: loss improved from 0.00355 to 0.00352, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 158/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00158: loss improved from 0.00352 to 0.00340, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 159/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00159: loss did not improve from 0.00340\n",
      "Epoch 160/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0036 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00160: loss did not improve from 0.00340\n",
      "Epoch 161/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0036 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.00340\n",
      "Epoch 162/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00162: loss did not improve from 0.00340\n",
      "Epoch 163/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00163: loss did not improve from 0.00340\n",
      "Epoch 164/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00164: loss improved from 0.00340 to 0.00339, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 165/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00165: loss did not improve from 0.00339\n",
      "Epoch 166/3000\n",
      "352/352 [==============================] - 86s 245ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00166: loss did not improve from 0.00339\n",
      "Epoch 167/3000\n",
      "352/352 [==============================] - 87s 246ms/step - loss: 0.0033 - velx_loss: 0.0016 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00167: loss improved from 0.00339 to 0.00333, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 168/3000\n",
      "352/352 [==============================] - 87s 246ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00168: loss did not improve from 0.00333\n",
      "Epoch 169/3000\n",
      "352/352 [==============================] - 87s 246ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00169: loss did not improve from 0.00333\n",
      "Epoch 170/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.00333\n",
      "Epoch 171/3000\n",
      "352/352 [==============================] - 86s 244ms/step - loss: 0.0035 - velx_loss: 0.0017 - vely_loss: 0.0018\n",
      "\n",
      "Epoch 00171: loss did not improve from 0.00333\n",
      "Epoch 172/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00172: loss did not improve from 0.00333\n",
      "Epoch 173/3000\n",
      "352/352 [==============================] - 86s 245ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00173: loss did not improve from 0.00333\n",
      "Epoch 174/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0033 - velx_loss: 0.0016 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00174: loss improved from 0.00333 to 0.00328, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 175/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0033 - velx_loss: 0.0016 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00175: loss did not improve from 0.00328\n",
      "Epoch 176/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0033 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00176: loss did not improve from 0.00328\n",
      "Epoch 177/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0033 - velx_loss: 0.0016 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00177: loss did not improve from 0.00328\n",
      "Epoch 178/3000\n",
      "352/352 [==============================] - 86s 245ms/step - loss: 0.0031 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00178: loss improved from 0.00328 to 0.00314, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 179/3000\n",
      "352/352 [==============================] - 87s 246ms/step - loss: 0.0033 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.00314\n",
      "Epoch 180/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00180: loss did not improve from 0.00314\n",
      "Epoch 181/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00181: loss did not improve from 0.00314\n",
      "Epoch 182/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00182: loss did not improve from 0.00314\n",
      "Epoch 183/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00183: loss improved from 0.00314 to 0.00313, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 184/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00184: loss improved from 0.00313 to 0.00309, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 185/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00185: loss did not improve from 0.00309\n",
      "Epoch 186/3000\n",
      "352/352 [==============================] - 86s 246ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00186: loss did not improve from 0.00309\n",
      "Epoch 187/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00187: loss did not improve from 0.00309\n",
      "Epoch 188/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0034 - velx_loss: 0.0017 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00188: loss did not improve from 0.00309\n",
      "Epoch 189/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0033 - velx_loss: 0.0016 - vely_loss: 0.0017\n",
      "\n",
      "Epoch 00189: loss did not improve from 0.00309\n",
      "Epoch 190/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00190: loss improved from 0.00309 to 0.00301, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 191/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00191: loss did not improve from 0.00301\n",
      "Epoch 192/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.00301\n",
      "Epoch 193/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00193: loss did not improve from 0.00301\n",
      "Epoch 194/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00194: loss did not improve from 0.00301\n",
      "Epoch 195/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00195: loss did not improve from 0.00301\n",
      "Epoch 196/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00196: loss did not improve from 0.00301\n",
      "Epoch 197/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00197: loss did not improve from 0.00301\n",
      "Epoch 198/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.00301\n",
      "Epoch 199/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0032 - velx_loss: 0.0016 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00199: loss did not improve from 0.00301\n",
      "Epoch 200/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00200: loss did not improve from 0.00301\n",
      "Epoch 201/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00201: loss improved from 0.00301 to 0.00292, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 202/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00202: loss did not improve from 0.00292\n",
      "Epoch 203/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00203: loss did not improve from 0.00292\n",
      "Epoch 204/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0016\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.00292\n",
      "Epoch 205/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.00292\n",
      "Epoch 206/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.00292\n",
      "Epoch 207/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00207: loss did not improve from 0.00292\n",
      "Epoch 208/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.00292\n",
      "Epoch 209/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00209: loss did not improve from 0.00292\n",
      "Epoch 210/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00210: loss did not improve from 0.00292\n",
      "Epoch 211/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00211: loss did not improve from 0.00292\n",
      "Epoch 212/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00212: loss did not improve from 0.00292\n",
      "Epoch 213/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0031 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00213: loss did not improve from 0.00292\n",
      "Epoch 214/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00214: loss improved from 0.00292 to 0.00290, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 215/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00215: loss did not improve from 0.00290\n",
      "Epoch 216/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00216: loss did not improve from 0.00290\n",
      "Epoch 217/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00217: loss did not improve from 0.00290\n",
      "Epoch 218/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00218: loss improved from 0.00290 to 0.00284, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 219/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.00284\n",
      "Epoch 220/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00220: loss improved from 0.00284 to 0.00274, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 221/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.00274\n",
      "Epoch 222/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00222: loss did not improve from 0.00274\n",
      "Epoch 223/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00223: loss did not improve from 0.00274\n",
      "Epoch 224/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00224: loss did not improve from 0.00274\n",
      "Epoch 225/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.00274\n",
      "Epoch 226/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.00274\n",
      "Epoch 227/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00227: loss did not improve from 0.00274\n",
      "Epoch 228/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0030 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.00274\n",
      "Epoch 229/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00229: loss did not improve from 0.00274\n",
      "Epoch 230/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.00274\n",
      "Epoch 231/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00231: loss did not improve from 0.00274\n",
      "Epoch 232/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0029 - velx_loss: 0.0015 - vely_loss: 0.0015\n",
      "\n",
      "Epoch 00232: loss did not improve from 0.00274\n",
      "Epoch 233/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.00274\n",
      "Epoch 234/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00234: loss did not improve from 0.00274\n",
      "Epoch 235/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00235: loss did not improve from 0.00274\n",
      "Epoch 236/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.00274\n",
      "Epoch 237/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00237: loss did not improve from 0.00274\n",
      "Epoch 238/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.00274\n",
      "Epoch 239/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00239: loss improved from 0.00274 to 0.00269, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 240/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00240: loss did not improve from 0.00269\n",
      "Epoch 241/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00241: loss did not improve from 0.00269\n",
      "Epoch 242/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00242: loss did not improve from 0.00269\n",
      "Epoch 243/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00243: loss did not improve from 0.00269\n",
      "Epoch 244/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.00269\n",
      "Epoch 245/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.00269\n",
      "Epoch 246/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00246: loss did not improve from 0.00269\n",
      "Epoch 247/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00247: loss did not improve from 0.00269\n",
      "Epoch 248/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.00269\n",
      "Epoch 249/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00249: loss improved from 0.00269 to 0.00265, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 250/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00250: loss did not improve from 0.00265\n",
      "Epoch 251/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00251: loss did not improve from 0.00265\n",
      "Epoch 252/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00252: loss did not improve from 0.00265\n",
      "Epoch 253/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00253: loss did not improve from 0.00265\n",
      "Epoch 254/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.00265\n",
      "Epoch 255/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00255: loss did not improve from 0.00265\n",
      "Epoch 256/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00256: loss did not improve from 0.00265\n",
      "Epoch 257/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00257: loss did not improve from 0.00265\n",
      "Epoch 258/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00258: loss did not improve from 0.00265\n",
      "Epoch 259/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00259: loss did not improve from 0.00265\n",
      "Epoch 260/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00260: loss improved from 0.00265 to 0.00251, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 261/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00261: loss did not improve from 0.00251\n",
      "Epoch 262/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00262: loss did not improve from 0.00251\n",
      "Epoch 263/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00263: loss did not improve from 0.00251\n",
      "Epoch 264/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00264: loss did not improve from 0.00251\n",
      "Epoch 265/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00265: loss did not improve from 0.00251\n",
      "Epoch 266/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00266: loss did not improve from 0.00251\n",
      "Epoch 267/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00267: loss did not improve from 0.00251\n",
      "Epoch 268/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00268: loss did not improve from 0.00251\n",
      "Epoch 269/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00269: loss did not improve from 0.00251\n",
      "Epoch 270/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00270: loss improved from 0.00251 to 0.00251, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 271/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00271: loss did not improve from 0.00251\n",
      "Epoch 272/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.00251\n",
      "Epoch 273/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0029 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00273: loss did not improve from 0.00251\n",
      "Epoch 274/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00274: loss did not improve from 0.00251\n",
      "Epoch 275/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.00251\n",
      "Epoch 276/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00276: loss improved from 0.00251 to 0.00249, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 277/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.00249\n",
      "Epoch 278/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.00249\n",
      "Epoch 279/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00279: loss did not improve from 0.00249\n",
      "Epoch 280/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.00249\n",
      "Epoch 281/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00281: loss did not improve from 0.00249\n",
      "Epoch 282/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00282: loss did not improve from 0.00249\n",
      "Epoch 283/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.00249\n",
      "Epoch 284/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00284: loss did not improve from 0.00249\n",
      "Epoch 285/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.00249\n",
      "Epoch 286/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00286: loss did not improve from 0.00249\n",
      "Epoch 287/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00287: loss improved from 0.00249 to 0.00249, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 288/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00288: loss did not improve from 0.00249\n",
      "Epoch 289/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0028 - velx_loss: 0.0014 - vely_loss: 0.0014\n",
      "\n",
      "Epoch 00289: loss did not improve from 0.00249\n",
      "Epoch 290/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00290: loss did not improve from 0.00249\n",
      "Epoch 291/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00291: loss did not improve from 0.00249\n",
      "Epoch 292/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00292: loss did not improve from 0.00249\n",
      "Epoch 293/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00293: loss improved from 0.00249 to 0.00248, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 294/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00294: loss did not improve from 0.00248\n",
      "Epoch 295/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00295: loss did not improve from 0.00248\n",
      "Epoch 296/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00296: loss did not improve from 0.00248\n",
      "Epoch 297/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00297: loss did not improve from 0.00248\n",
      "Epoch 298/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00298: loss improved from 0.00248 to 0.00236, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 299/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.00236\n",
      "Epoch 300/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.00236\n",
      "Epoch 301/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00301: loss did not improve from 0.00236\n",
      "Epoch 302/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00302: loss did not improve from 0.00236\n",
      "Epoch 303/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.00236\n",
      "Epoch 304/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00304: loss did not improve from 0.00236\n",
      "Epoch 305/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.00236\n",
      "Epoch 306/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00306: loss did not improve from 0.00236\n",
      "Epoch 307/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.00236\n",
      "Epoch 308/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0027 - velx_loss: 0.0014 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00308: loss did not improve from 0.00236\n",
      "Epoch 309/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00309: loss did not improve from 0.00236\n",
      "Epoch 310/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00310: loss did not improve from 0.00236\n",
      "Epoch 311/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00311: loss improved from 0.00236 to 0.00223, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 312/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.00223\n",
      "Epoch 313/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.00223\n",
      "Epoch 314/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00314: loss did not improve from 0.00223\n",
      "Epoch 315/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.00223\n",
      "Epoch 316/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00316: loss did not improve from 0.00223\n",
      "Epoch 317/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00317: loss did not improve from 0.00223\n",
      "Epoch 318/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.00223\n",
      "Epoch 319/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00319: loss did not improve from 0.00223\n",
      "Epoch 320/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00320: loss did not improve from 0.00223\n",
      "Epoch 321/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00321: loss did not improve from 0.00223\n",
      "Epoch 322/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.00223\n",
      "Epoch 323/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.00223\n",
      "Epoch 324/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00324: loss did not improve from 0.00223\n",
      "Epoch 325/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.00223\n",
      "Epoch 326/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00326: loss did not improve from 0.00223\n",
      "Epoch 327/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.00223\n",
      "Epoch 328/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00328: loss did not improve from 0.00223\n",
      "Epoch 329/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00329: loss did not improve from 0.00223\n",
      "Epoch 330/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.00223\n",
      "Epoch 331/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00331: loss did not improve from 0.00223\n",
      "Epoch 332/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00332: loss did not improve from 0.00223\n",
      "Epoch 333/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00333: loss did not improve from 0.00223\n",
      "Epoch 334/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0026 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.00223\n",
      "Epoch 335/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.00223\n",
      "Epoch 336/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00336: loss did not improve from 0.00223\n",
      "Epoch 337/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00337: loss did not improve from 0.00223\n",
      "Epoch 338/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.00223\n",
      "Epoch 339/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00339: loss did not improve from 0.00223\n",
      "Epoch 340/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.00223\n",
      "Epoch 341/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00341: loss did not improve from 0.00223\n",
      "Epoch 342/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.00223\n",
      "Epoch 343/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0013\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.00223\n",
      "Epoch 344/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00344: loss did not improve from 0.00223\n",
      "Epoch 345/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00345: loss did not improve from 0.00223\n",
      "Epoch 346/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00346: loss did not improve from 0.00223\n",
      "Epoch 347/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.00223\n",
      "Epoch 348/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00348: loss improved from 0.00223 to 0.00221, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 349/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00349: loss did not improve from 0.00221\n",
      "Epoch 350/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.00221\n",
      "Epoch 351/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00351: loss did not improve from 0.00221\n",
      "Epoch 352/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.00221\n",
      "Epoch 353/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00353: loss did not improve from 0.00221\n",
      "Epoch 354/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.00221\n",
      "Epoch 355/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.00221\n",
      "Epoch 356/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00356: loss did not improve from 0.00221\n",
      "Epoch 357/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.00221\n",
      "Epoch 358/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00358: loss improved from 0.00221 to 0.00219, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 359/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00359: loss improved from 0.00219 to 0.00217, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 360/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00360: loss improved from 0.00217 to 0.00214, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 361/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00361: loss did not improve from 0.00214\n",
      "Epoch 362/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00362: loss did not improve from 0.00214\n",
      "Epoch 363/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0025 - velx_loss: 0.0013 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00363: loss did not improve from 0.00214\n",
      "Epoch 364/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00364: loss did not improve from 0.00214\n",
      "Epoch 365/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.00214\n",
      "Epoch 366/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.00214\n",
      "Epoch 367/3000\n",
      "352/352 [==============================] - 93s 263ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00367: loss did not improve from 0.00214\n",
      "Epoch 368/3000\n",
      "352/352 [==============================] - 92s 262ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.00214\n",
      "Epoch 369/3000\n",
      "352/352 [==============================] - 92s 260ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.00214\n",
      "Epoch 370/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.00214\n",
      "Epoch 371/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00371: loss did not improve from 0.00214\n",
      "Epoch 372/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00372: loss did not improve from 0.00214\n",
      "Epoch 373/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.00214\n",
      "Epoch 374/3000\n",
      "352/352 [==============================] - 90s 257ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00374: loss did not improve from 0.00214\n",
      "Epoch 375/3000\n",
      "352/352 [==============================] - 91s 259ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.00214\n",
      "Epoch 376/3000\n",
      "352/352 [==============================] - 91s 257ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00376: loss did not improve from 0.00214\n",
      "Epoch 377/3000\n",
      "352/352 [==============================] - 91s 258ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.00214\n",
      "Epoch 378/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00378: loss did not improve from 0.00214\n",
      "Epoch 379/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.00214\n",
      "Epoch 380/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00380: loss did not improve from 0.00214\n",
      "Epoch 381/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00381: loss did not improve from 0.00214\n",
      "Epoch 382/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00382: loss did not improve from 0.00214\n",
      "Epoch 383/3000\n",
      "352/352 [==============================] - 90s 254ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00383: loss did not improve from 0.00214\n",
      "Epoch 384/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.00214\n",
      "Epoch 385/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00385: loss did not improve from 0.00214\n",
      "Epoch 386/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.00214\n",
      "Epoch 387/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.00214\n",
      "Epoch 388/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.00214\n",
      "Epoch 389/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00389: loss did not improve from 0.00214\n",
      "Epoch 390/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.00214\n",
      "Epoch 391/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00391: loss did not improve from 0.00214\n",
      "Epoch 392/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.00214\n",
      "Epoch 393/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.00214\n",
      "Epoch 394/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.00214\n",
      "Epoch 395/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00395: loss did not improve from 0.00214\n",
      "Epoch 396/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.00214\n",
      "Epoch 397/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00397: loss did not improve from 0.00214\n",
      "Epoch 398/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00398: loss improved from 0.00214 to 0.00206, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 399/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0024 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.00206\n",
      "Epoch 400/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00400: loss did not improve from 0.00206\n",
      "Epoch 401/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.00206\n",
      "Epoch 402/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.00206\n",
      "Epoch 403/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00403: loss did not improve from 0.00206\n",
      "Epoch 404/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00404: loss did not improve from 0.00206\n",
      "Epoch 405/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00405: loss did not improve from 0.00206\n",
      "Epoch 406/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.00206\n",
      "Epoch 407/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00407: loss did not improve from 0.00206\n",
      "Epoch 408/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.00206\n",
      "Epoch 409/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.00206\n",
      "Epoch 410/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00410: loss did not improve from 0.00206\n",
      "Epoch 411/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.00206\n",
      "Epoch 412/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00412: loss did not improve from 0.00206\n",
      "Epoch 413/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.00206\n",
      "Epoch 414/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00414: loss did not improve from 0.00206\n",
      "Epoch 415/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.00206\n",
      "Epoch 416/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.00206\n",
      "Epoch 417/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00417: loss did not improve from 0.00206\n",
      "Epoch 418/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.00206\n",
      "Epoch 419/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.00206\n",
      "Epoch 420/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00420: loss improved from 0.00206 to 0.00204, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 421/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00421: loss did not improve from 0.00204\n",
      "Epoch 422/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00422: loss improved from 0.00204 to 0.00202, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 423/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.00202\n",
      "Epoch 424/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0025 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.00202\n",
      "Epoch 425/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.00202\n",
      "Epoch 426/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00426: loss did not improve from 0.00202\n",
      "Epoch 427/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.8212e-04 - vely_loss: 9.8395e-04\n",
      "\n",
      "Epoch 00427: loss improved from 0.00202 to 0.00197, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 428/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.00197\n",
      "Epoch 429/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.00197\n",
      "Epoch 430/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.00197\n",
      "Epoch 431/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.8879e-04 - vely_loss: 9.9464e-04\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.00197\n",
      "Epoch 432/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00432: loss did not improve from 0.00197\n",
      "Epoch 433/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00433: loss did not improve from 0.00197\n",
      "Epoch 434/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00434: loss did not improve from 0.00197\n",
      "Epoch 435/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00435: loss did not improve from 0.00197\n",
      "Epoch 436/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00436: loss did not improve from 0.00197\n",
      "Epoch 437/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.00197\n",
      "Epoch 438/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0012\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.00197\n",
      "Epoch 439/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.00197\n",
      "Epoch 440/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.00197\n",
      "Epoch 441/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00441: loss did not improve from 0.00197\n",
      "Epoch 442/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00442: loss did not improve from 0.00197\n",
      "Epoch 443/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00443: loss did not improve from 0.00197\n",
      "Epoch 444/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.00197\n",
      "Epoch 445/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.00197\n",
      "Epoch 446/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.00197\n",
      "Epoch 447/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.00197\n",
      "Epoch 448/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00448: loss did not improve from 0.00197\n",
      "Epoch 449/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.00197\n",
      "Epoch 450/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.00197\n",
      "Epoch 451/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.8751e-04 - vely_loss: 9.7614e-04\n",
      "\n",
      "Epoch 00451: loss improved from 0.00197 to 0.00196, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 452/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.9654e-04 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.00196\n",
      "Epoch 453/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.00196\n",
      "Epoch 454/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.00196\n",
      "Epoch 455/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00455: loss did not improve from 0.00196\n",
      "Epoch 456/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00456: loss did not improve from 0.00196\n",
      "Epoch 457/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00457: loss did not improve from 0.00196\n",
      "Epoch 458/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.00196\n",
      "Epoch 459/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00459: loss did not improve from 0.00196\n",
      "Epoch 460/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.00196\n",
      "Epoch 461/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.00196\n",
      "Epoch 462/3000\n",
      "352/352 [==============================] - 90s 254ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.00196\n",
      "Epoch 463/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.00196\n",
      "Epoch 464/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.9633e-04 - vely_loss: 9.8650e-04\n",
      "\n",
      "Epoch 00464: loss did not improve from 0.00196\n",
      "Epoch 465/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.00196\n",
      "Epoch 466/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00466: loss did not improve from 0.00196\n",
      "Epoch 467/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00467: loss did not improve from 0.00196\n",
      "Epoch 468/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00468: loss did not improve from 0.00196\n",
      "Epoch 469/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0023 - velx_loss: 0.0012 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00469: loss did not improve from 0.00196\n",
      "Epoch 470/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00470: loss did not improve from 0.00196\n",
      "Epoch 471/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.4667e-04 - vely_loss: 9.5987e-04\n",
      "\n",
      "Epoch 00471: loss improved from 0.00196 to 0.00191, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 472/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 9.9779e-04 - vely_loss: 9.8469e-04\n",
      "\n",
      "Epoch 00472: loss did not improve from 0.00191\n",
      "Epoch 473/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9676e-04\n",
      "\n",
      "Epoch 00473: loss did not improve from 0.00191\n",
      "Epoch 474/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00474: loss did not improve from 0.00191\n",
      "Epoch 475/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.00191\n",
      "Epoch 476/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00476: loss did not improve from 0.00191\n",
      "Epoch 477/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00477: loss did not improve from 0.00191\n",
      "Epoch 478/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00478: loss did not improve from 0.00191\n",
      "Epoch 479/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00479: loss did not improve from 0.00191\n",
      "Epoch 480/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00480: loss did not improve from 0.00191\n",
      "Epoch 481/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 9.9713e-04 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00481: loss did not improve from 0.00191\n",
      "Epoch 482/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00482: loss did not improve from 0.00191\n",
      "Epoch 483/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00483: loss did not improve from 0.00191\n",
      "Epoch 484/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00484: loss did not improve from 0.00191\n",
      "Epoch 485/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00485: loss did not improve from 0.00191\n",
      "Epoch 486/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00486: loss did not improve from 0.00191\n",
      "Epoch 487/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0020 - velx_loss: 9.9709e-04 - vely_loss: 9.9554e-04\n",
      "\n",
      "Epoch 00487: loss did not improve from 0.00191\n",
      "Epoch 488/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00488: loss did not improve from 0.00191\n",
      "Epoch 489/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00489: loss did not improve from 0.00191\n",
      "Epoch 490/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00490: loss did not improve from 0.00191\n",
      "Epoch 491/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00491: loss did not improve from 0.00191\n",
      "Epoch 492/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00492: loss did not improve from 0.00191\n",
      "Epoch 493/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00493: loss did not improve from 0.00191\n",
      "Epoch 494/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00494: loss did not improve from 0.00191\n",
      "Epoch 495/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00495: loss did not improve from 0.00191\n",
      "Epoch 496/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 9.9892e-04 - vely_loss: 9.8826e-04\n",
      "\n",
      "Epoch 00496: loss did not improve from 0.00191\n",
      "Epoch 497/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00497: loss did not improve from 0.00191\n",
      "Epoch 498/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 9.8014e-04 - vely_loss: 9.8059e-04\n",
      "\n",
      "Epoch 00498: loss did not improve from 0.00191\n",
      "Epoch 499/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00499: loss did not improve from 0.00191\n",
      "Epoch 500/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.00191\n",
      "Epoch 501/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00501: loss did not improve from 0.00191\n",
      "Epoch 502/3000\n",
      "352/352 [==============================] - 90s 254ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00502: loss did not improve from 0.00191\n",
      "Epoch 503/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00503: loss did not improve from 0.00191\n",
      "Epoch 504/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00504: loss did not improve from 0.00191\n",
      "Epoch 505/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.2625e-04 - vely_loss: 9.3799e-04\n",
      "\n",
      "Epoch 00505: loss improved from 0.00191 to 0.00186, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 506/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3119e-04 - vely_loss: 9.2620e-04\n",
      "\n",
      "Epoch 00506: loss improved from 0.00186 to 0.00186, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 507/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.6748e-04 - vely_loss: 9.5365e-04\n",
      "\n",
      "Epoch 00507: loss did not improve from 0.00186\n",
      "Epoch 508/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.7999e-04 - vely_loss: 9.8166e-04\n",
      "\n",
      "Epoch 00508: loss did not improve from 0.00186\n",
      "Epoch 509/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9661e-04\n",
      "\n",
      "Epoch 00509: loss did not improve from 0.00186\n",
      "Epoch 510/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00510: loss did not improve from 0.00186\n",
      "Epoch 511/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00511: loss did not improve from 0.00186\n",
      "Epoch 512/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.8582e-04 - vely_loss: 9.7898e-04\n",
      "\n",
      "Epoch 00512: loss did not improve from 0.00186\n",
      "Epoch 513/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00513: loss did not improve from 0.00186\n",
      "Epoch 514/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00514: loss did not improve from 0.00186\n",
      "Epoch 515/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00515: loss did not improve from 0.00186\n",
      "Epoch 516/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.3669e-04 - vely_loss: 9.2867e-04\n",
      "\n",
      "Epoch 00516: loss did not improve from 0.00186\n",
      "Epoch 517/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.9992e-04 - vely_loss: 9.9766e-04\n",
      "\n",
      "Epoch 00517: loss did not improve from 0.00186\n",
      "Epoch 518/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.7977e-04 - vely_loss: 9.8506e-04\n",
      "\n",
      "Epoch 00518: loss did not improve from 0.00186\n",
      "Epoch 519/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9325e-04\n",
      "\n",
      "Epoch 00519: loss did not improve from 0.00186\n",
      "Epoch 520/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00520: loss did not improve from 0.00186\n",
      "Epoch 521/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00521: loss did not improve from 0.00186\n",
      "Epoch 522/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.6879e-04 - vely_loss: 9.6809e-04\n",
      "\n",
      "Epoch 00522: loss did not improve from 0.00186\n",
      "Epoch 523/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.9161e-04 - vely_loss: 9.8824e-04\n",
      "\n",
      "Epoch 00523: loss did not improve from 0.00186\n",
      "Epoch 524/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00524: loss did not improve from 0.00186\n",
      "Epoch 525/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00525: loss did not improve from 0.00186\n",
      "Epoch 526/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.6813e-04 - vely_loss: 9.7144e-04\n",
      "\n",
      "Epoch 00526: loss did not improve from 0.00186\n",
      "Epoch 527/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00527: loss did not improve from 0.00186\n",
      "Epoch 528/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.8592e-04 - vely_loss: 9.7013e-04\n",
      "\n",
      "Epoch 00528: loss did not improve from 0.00186\n",
      "Epoch 529/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00529: loss did not improve from 0.00186\n",
      "Epoch 530/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.8515e-04 - vely_loss: 9.7522e-04\n",
      "\n",
      "Epoch 00530: loss did not improve from 0.00186\n",
      "Epoch 531/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00531: loss did not improve from 0.00186\n",
      "Epoch 532/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00532: loss did not improve from 0.00186\n",
      "Epoch 533/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.7530e-04 - vely_loss: 9.7495e-04\n",
      "\n",
      "Epoch 00533: loss did not improve from 0.00186\n",
      "Epoch 534/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.5826e-04 - vely_loss: 9.5370e-04\n",
      "\n",
      "Epoch 00534: loss did not improve from 0.00186\n",
      "Epoch 535/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.8758e-04 - vely_loss: 9.6845e-04\n",
      "\n",
      "Epoch 00535: loss did not improve from 0.00186\n",
      "Epoch 536/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.4362e-04 - vely_loss: 9.5776e-04\n",
      "\n",
      "Epoch 00536: loss did not improve from 0.00186\n",
      "Epoch 537/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6403e-04 - vely_loss: 9.6488e-04\n",
      "\n",
      "Epoch 00537: loss did not improve from 0.00186\n",
      "Epoch 538/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.9964e-04 - vely_loss: 9.7958e-04\n",
      "\n",
      "Epoch 00538: loss did not improve from 0.00186\n",
      "Epoch 539/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.4447e-04 - vely_loss: 9.5588e-04\n",
      "\n",
      "Epoch 00539: loss did not improve from 0.00186\n",
      "Epoch 540/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.5049e-04 - vely_loss: 9.5258e-04\n",
      "\n",
      "Epoch 00540: loss did not improve from 0.00186\n",
      "Epoch 541/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0020 - velx_loss: 9.8193e-04 - vely_loss: 9.6827e-04\n",
      "\n",
      "Epoch 00541: loss did not improve from 0.00186\n",
      "Epoch 542/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00542: loss did not improve from 0.00186\n",
      "Epoch 543/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00543: loss did not improve from 0.00186\n",
      "Epoch 544/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00544: loss did not improve from 0.00186\n",
      "Epoch 545/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.7236e-04 - vely_loss: 9.6584e-04\n",
      "\n",
      "Epoch 00545: loss did not improve from 0.00186\n",
      "Epoch 546/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00546: loss did not improve from 0.00186\n",
      "Epoch 547/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00547: loss did not improve from 0.00186\n",
      "Epoch 548/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.8366e-04 - vely_loss: 9.6691e-04\n",
      "\n",
      "Epoch 00548: loss did not improve from 0.00186\n",
      "Epoch 549/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.7207e-04 - vely_loss: 9.5871e-04\n",
      "\n",
      "Epoch 00549: loss did not improve from 0.00186\n",
      "Epoch 550/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.5247e-04 - vely_loss: 9.6171e-04\n",
      "\n",
      "Epoch 00550: loss did not improve from 0.00186\n",
      "Epoch 551/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.8832e-04\n",
      "\n",
      "Epoch 00551: loss did not improve from 0.00186\n",
      "Epoch 552/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.8117e-04 - vely_loss: 9.8997e-04\n",
      "\n",
      "Epoch 00552: loss did not improve from 0.00186\n",
      "Epoch 553/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.7270e-04 - vely_loss: 9.5342e-04\n",
      "\n",
      "Epoch 00553: loss did not improve from 0.00186\n",
      "Epoch 554/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.9624e-04 - vely_loss: 9.7389e-04\n",
      "\n",
      "Epoch 00554: loss did not improve from 0.00186\n",
      "Epoch 555/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.6855e-04 - vely_loss: 9.8307e-04\n",
      "\n",
      "Epoch 00555: loss did not improve from 0.00186\n",
      "Epoch 556/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00556: loss did not improve from 0.00186\n",
      "Epoch 557/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.7175e-04\n",
      "\n",
      "Epoch 00557: loss did not improve from 0.00186\n",
      "Epoch 558/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 9.7431e-04 - vely_loss: 9.8048e-04\n",
      "\n",
      "Epoch 00558: loss did not improve from 0.00186\n",
      "Epoch 559/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.7626e-04 - vely_loss: 9.7664e-04\n",
      "\n",
      "Epoch 00559: loss did not improve from 0.00186\n",
      "Epoch 560/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00560: loss did not improve from 0.00186\n",
      "Epoch 561/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9796e-04\n",
      "\n",
      "Epoch 00561: loss did not improve from 0.00186\n",
      "Epoch 562/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.5205e-04 - vely_loss: 9.3556e-04\n",
      "\n",
      "Epoch 00562: loss did not improve from 0.00186\n",
      "Epoch 563/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1282e-04 - vely_loss: 9.0009e-04\n",
      "\n",
      "Epoch 00563: loss improved from 0.00186 to 0.00181, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 564/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.5496e-04 - vely_loss: 9.4280e-04\n",
      "\n",
      "Epoch 00564: loss did not improve from 0.00181\n",
      "Epoch 565/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.8694e-04 - vely_loss: 9.9003e-04\n",
      "\n",
      "Epoch 00565: loss did not improve from 0.00181\n",
      "Epoch 566/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00566: loss did not improve from 0.00181\n",
      "Epoch 567/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.9538e-04 - vely_loss: 9.7112e-04\n",
      "\n",
      "Epoch 00567: loss did not improve from 0.00181\n",
      "Epoch 568/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.8870e-04 - vely_loss: 9.8069e-04\n",
      "\n",
      "Epoch 00568: loss did not improve from 0.00181\n",
      "Epoch 569/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.7384e-04 - vely_loss: 9.8139e-04\n",
      "\n",
      "Epoch 00569: loss did not improve from 0.00181\n",
      "Epoch 570/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 9.9799e-04 - vely_loss: 9.8620e-04\n",
      "\n",
      "Epoch 00570: loss did not improve from 0.00181\n",
      "Epoch 571/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.6830e-04 - vely_loss: 9.4568e-04\n",
      "\n",
      "Epoch 00571: loss did not improve from 0.00181\n",
      "Epoch 572/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.9389e-04 - vely_loss: 9.6174e-04\n",
      "\n",
      "Epoch 00572: loss did not improve from 0.00181\n",
      "Epoch 573/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6746e-04 - vely_loss: 9.5731e-04\n",
      "\n",
      "Epoch 00573: loss did not improve from 0.00181\n",
      "Epoch 574/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 9.9092e-04 - vely_loss: 9.7587e-04\n",
      "\n",
      "Epoch 00574: loss did not improve from 0.00181\n",
      "Epoch 575/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00575: loss did not improve from 0.00181\n",
      "Epoch 576/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.7022e-04 - vely_loss: 9.6963e-04\n",
      "\n",
      "Epoch 00576: loss did not improve from 0.00181\n",
      "Epoch 577/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.9192e-04 - vely_loss: 9.8329e-04\n",
      "\n",
      "Epoch 00577: loss did not improve from 0.00181\n",
      "Epoch 578/3000\n",
      "352/352 [==============================] - 90s 256ms/step - loss: 0.0019 - velx_loss: 9.4229e-04 - vely_loss: 9.1545e-04\n",
      "\n",
      "Epoch 00578: loss did not improve from 0.00181\n",
      "Epoch 579/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0019 - velx_loss: 9.5054e-04 - vely_loss: 9.6163e-04\n",
      "\n",
      "Epoch 00579: loss did not improve from 0.00181\n",
      "Epoch 580/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 9.8680e-04 - vely_loss: 9.7351e-04\n",
      "\n",
      "Epoch 00580: loss did not improve from 0.00181\n",
      "Epoch 581/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00581: loss did not improve from 0.00181\n",
      "Epoch 582/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.4415e-04 - vely_loss: 9.4216e-04\n",
      "\n",
      "Epoch 00582: loss did not improve from 0.00181\n",
      "Epoch 583/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.1367e-04 - vely_loss: 9.0500e-04\n",
      "\n",
      "Epoch 00583: loss did not improve from 0.00181\n",
      "Epoch 584/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0019 - velx_loss: 9.5133e-04 - vely_loss: 9.5375e-04\n",
      "\n",
      "Epoch 00584: loss did not improve from 0.00181\n",
      "Epoch 585/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.4188e-04 - vely_loss: 9.4038e-04\n",
      "\n",
      "Epoch 00585: loss did not improve from 0.00181\n",
      "Epoch 586/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00586: loss did not improve from 0.00181\n",
      "Epoch 587/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.8441e-04 - vely_loss: 9.7367e-04\n",
      "\n",
      "Epoch 00587: loss did not improve from 0.00181\n",
      "Epoch 588/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3885e-04 - vely_loss: 9.3036e-04\n",
      "\n",
      "Epoch 00588: loss did not improve from 0.00181\n",
      "Epoch 589/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.5666e-04 - vely_loss: 9.4973e-04\n",
      "\n",
      "Epoch 00589: loss did not improve from 0.00181\n",
      "Epoch 590/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0019 - velx_loss: 9.6849e-04 - vely_loss: 9.6482e-04\n",
      "\n",
      "Epoch 00590: loss did not improve from 0.00181\n",
      "Epoch 591/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.8108e-04 - vely_loss: 9.6190e-04\n",
      "\n",
      "Epoch 00591: loss did not improve from 0.00181\n",
      "Epoch 592/3000\n",
      "352/352 [==============================] - 90s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00592: loss did not improve from 0.00181\n",
      "Epoch 593/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.3588e-04 - vely_loss: 9.4407e-04\n",
      "\n",
      "Epoch 00593: loss did not improve from 0.00181\n",
      "Epoch 594/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0018 - velx_loss: 9.1836e-04 - vely_loss: 9.1369e-04\n",
      "\n",
      "Epoch 00594: loss did not improve from 0.00181\n",
      "Epoch 595/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.7692e-04 - vely_loss: 9.8034e-04\n",
      "\n",
      "Epoch 00595: loss did not improve from 0.00181\n",
      "Epoch 596/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.6655e-04 - vely_loss: 9.5175e-04\n",
      "\n",
      "Epoch 00596: loss did not improve from 0.00181\n",
      "Epoch 597/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0020 - velx_loss: 9.7536e-04 - vely_loss: 9.7539e-04\n",
      "\n",
      "Epoch 00597: loss did not improve from 0.00181\n",
      "Epoch 598/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.9950e-04 - vely_loss: 9.7058e-04\n",
      "\n",
      "Epoch 00598: loss did not improve from 0.00181\n",
      "Epoch 599/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9789e-04\n",
      "\n",
      "Epoch 00599: loss did not improve from 0.00181\n",
      "Epoch 600/3000\n",
      "352/352 [==============================] - 90s 254ms/step - loss: 0.0020 - velx_loss: 9.9161e-04 - vely_loss: 9.7117e-04\n",
      "\n",
      "Epoch 00600: loss did not improve from 0.00181\n",
      "Epoch 601/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.4098e-04 - vely_loss: 9.4601e-04\n",
      "\n",
      "Epoch 00601: loss did not improve from 0.00181\n",
      "Epoch 602/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.2059e-04 - vely_loss: 9.1702e-04\n",
      "\n",
      "Epoch 00602: loss did not improve from 0.00181\n",
      "Epoch 603/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.2412e-04 - vely_loss: 9.1630e-04\n",
      "\n",
      "Epoch 00603: loss did not improve from 0.00181\n",
      "Epoch 604/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.6307e-04 - vely_loss: 9.4844e-04\n",
      "\n",
      "Epoch 00604: loss did not improve from 0.00181\n",
      "Epoch 605/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00605: loss did not improve from 0.00181\n",
      "Epoch 606/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0018 - velx_loss: 9.1869e-04 - vely_loss: 9.0816e-04\n",
      "\n",
      "Epoch 00606: loss did not improve from 0.00181\n",
      "Epoch 607/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.8649e-04 - vely_loss: 8.8985e-04\n",
      "\n",
      "Epoch 00607: loss improved from 0.00181 to 0.00178, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 608/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.2983e-04 - vely_loss: 9.1761e-04\n",
      "\n",
      "Epoch 00608: loss did not improve from 0.00178\n",
      "Epoch 609/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.9173e-04 - vely_loss: 9.7709e-04\n",
      "\n",
      "Epoch 00609: loss did not improve from 0.00178\n",
      "Epoch 610/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00610: loss did not improve from 0.00178\n",
      "Epoch 611/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00611: loss did not improve from 0.00178\n",
      "Epoch 612/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00612: loss did not improve from 0.00178\n",
      "Epoch 613/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.9905e-04 - vely_loss: 9.0113e-04\n",
      "\n",
      "Epoch 00613: loss did not improve from 0.00178\n",
      "Epoch 614/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.6000e-04 - vely_loss: 8.7392e-04\n",
      "\n",
      "Epoch 00614: loss improved from 0.00178 to 0.00173, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 615/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3366e-04 - vely_loss: 9.2336e-04\n",
      "\n",
      "Epoch 00615: loss did not improve from 0.00173\n",
      "Epoch 616/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3954e-04 - vely_loss: 9.3499e-04\n",
      "\n",
      "Epoch 00616: loss did not improve from 0.00173\n",
      "Epoch 617/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9045e-04\n",
      "\n",
      "Epoch 00617: loss did not improve from 0.00173\n",
      "Epoch 618/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00618: loss did not improve from 0.00173\n",
      "Epoch 619/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00619: loss did not improve from 0.00173\n",
      "Epoch 620/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.7635e-04 - vely_loss: 9.7650e-04\n",
      "\n",
      "Epoch 00620: loss did not improve from 0.00173\n",
      "Epoch 621/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.3162e-04 - vely_loss: 9.1294e-04\n",
      "\n",
      "Epoch 00621: loss did not improve from 0.00173\n",
      "Epoch 622/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.7228e-04 - vely_loss: 8.7061e-04\n",
      "\n",
      "Epoch 00622: loss did not improve from 0.00173\n",
      "Epoch 623/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.5396e-04 - vely_loss: 8.5077e-04\n",
      "\n",
      "Epoch 00623: loss improved from 0.00173 to 0.00170, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 624/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0019 - velx_loss: 9.2385e-04 - vely_loss: 9.2908e-04\n",
      "\n",
      "Epoch 00624: loss did not improve from 0.00170\n",
      "Epoch 625/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.8508e-04\n",
      "\n",
      "Epoch 00625: loss did not improve from 0.00170\n",
      "Epoch 626/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.5303e-04 - vely_loss: 9.5212e-04\n",
      "\n",
      "Epoch 00626: loss did not improve from 0.00170\n",
      "Epoch 627/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6030e-04 - vely_loss: 9.6119e-04\n",
      "\n",
      "Epoch 00627: loss did not improve from 0.00170\n",
      "Epoch 628/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3906e-04 - vely_loss: 9.3465e-04\n",
      "\n",
      "Epoch 00628: loss did not improve from 0.00170\n",
      "Epoch 629/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 8.8340e-04 - vely_loss: 8.8423e-04\n",
      "\n",
      "Epoch 00629: loss did not improve from 0.00170\n",
      "Epoch 630/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.8675e-04 - vely_loss: 8.8295e-04\n",
      "\n",
      "Epoch 00630: loss did not improve from 0.00170\n",
      "Epoch 631/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.3600e-04 - vely_loss: 9.3084e-04\n",
      "\n",
      "Epoch 00631: loss did not improve from 0.00170\n",
      "Epoch 632/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.8891e-04 - vely_loss: 9.8833e-04\n",
      "\n",
      "Epoch 00632: loss did not improve from 0.00170\n",
      "Epoch 633/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0020 - velx_loss: 9.9008e-04 - vely_loss: 9.8895e-04\n",
      "\n",
      "Epoch 00633: loss did not improve from 0.00170\n",
      "Epoch 634/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0021 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00634: loss did not improve from 0.00170\n",
      "Epoch 635/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.2414e-04 - vely_loss: 9.3192e-04\n",
      "\n",
      "Epoch 00635: loss did not improve from 0.00170\n",
      "Epoch 636/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.3207e-04 - vely_loss: 9.2320e-04\n",
      "\n",
      "Epoch 00636: loss did not improve from 0.00170\n",
      "Epoch 637/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0018 - velx_loss: 9.1772e-04 - vely_loss: 9.2572e-04\n",
      "\n",
      "Epoch 00637: loss did not improve from 0.00170\n",
      "Epoch 638/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.2199e-04 - vely_loss: 9.3150e-04\n",
      "\n",
      "Epoch 00638: loss did not improve from 0.00170\n",
      "Epoch 639/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.1532e-04 - vely_loss: 9.2120e-04\n",
      "\n",
      "Epoch 00639: loss did not improve from 0.00170\n",
      "Epoch 640/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.7169e-04 - vely_loss: 9.5761e-04\n",
      "\n",
      "Epoch 00640: loss did not improve from 0.00170\n",
      "Epoch 641/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0019 - velx_loss: 9.7953e-04 - vely_loss: 9.6684e-04\n",
      "\n",
      "Epoch 00641: loss did not improve from 0.00170\n",
      "Epoch 642/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.5596e-04 - vely_loss: 9.5480e-04\n",
      "\n",
      "Epoch 00642: loss did not improve from 0.00170\n",
      "Epoch 643/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.0883e-04 - vely_loss: 8.9182e-04\n",
      "\n",
      "Epoch 00643: loss did not improve from 0.00170\n",
      "Epoch 644/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0020 - velx_loss: 9.8765e-04 - vely_loss: 9.7403e-04\n",
      "\n",
      "Epoch 00644: loss did not improve from 0.00170\n",
      "Epoch 645/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0020 - velx_loss: 9.8129e-04 - vely_loss: 9.9626e-04\n",
      "\n",
      "Epoch 00645: loss did not improve from 0.00170\n",
      "Epoch 646/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.4519e-04 - vely_loss: 9.4498e-04\n",
      "\n",
      "Epoch 00646: loss did not improve from 0.00170\n",
      "Epoch 647/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.4501e-04 - vely_loss: 9.3876e-04\n",
      "\n",
      "Epoch 00647: loss did not improve from 0.00170\n",
      "Epoch 648/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.4296e-04 - vely_loss: 9.5093e-04\n",
      "\n",
      "Epoch 00648: loss did not improve from 0.00170\n",
      "Epoch 649/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9508e-04\n",
      "\n",
      "Epoch 00649: loss did not improve from 0.00170\n",
      "Epoch 650/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9101e-04\n",
      "\n",
      "Epoch 00650: loss did not improve from 0.00170\n",
      "Epoch 651/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.0912e-04 - vely_loss: 9.0772e-04\n",
      "\n",
      "Epoch 00651: loss did not improve from 0.00170\n",
      "Epoch 652/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0017 - velx_loss: 8.4174e-04 - vely_loss: 8.5408e-04\n",
      "\n",
      "Epoch 00652: loss improved from 0.00170 to 0.00170, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 653/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.0700e-04 - vely_loss: 8.8929e-04\n",
      "\n",
      "Epoch 00653: loss did not improve from 0.00170\n",
      "Epoch 654/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.7099e-04 - vely_loss: 8.6604e-04\n",
      "\n",
      "Epoch 00654: loss did not improve from 0.00170\n",
      "Epoch 655/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.0172e-04 - vely_loss: 9.0212e-04\n",
      "\n",
      "Epoch 00655: loss did not improve from 0.00170\n",
      "Epoch 656/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9582e-04\n",
      "\n",
      "Epoch 00656: loss did not improve from 0.00170\n",
      "Epoch 657/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.7967e-04 - vely_loss: 9.5841e-04\n",
      "\n",
      "Epoch 00657: loss did not improve from 0.00170\n",
      "Epoch 658/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9993e-04\n",
      "\n",
      "Epoch 00658: loss did not improve from 0.00170\n",
      "Epoch 659/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.4054e-04 - vely_loss: 9.3703e-04\n",
      "\n",
      "Epoch 00659: loss did not improve from 0.00170\n",
      "Epoch 660/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.3358e-04 - vely_loss: 9.2682e-04\n",
      "\n",
      "Epoch 00660: loss did not improve from 0.00170\n",
      "Epoch 661/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.6913e-04 - vely_loss: 9.6607e-04\n",
      "\n",
      "Epoch 00661: loss did not improve from 0.00170\n",
      "Epoch 662/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.2139e-04 - vely_loss: 9.1778e-04\n",
      "\n",
      "Epoch 00662: loss did not improve from 0.00170\n",
      "Epoch 663/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.7460e-04 - vely_loss: 8.8820e-04\n",
      "\n",
      "Epoch 00663: loss did not improve from 0.00170\n",
      "Epoch 664/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1038e-04 - vely_loss: 8.9471e-04\n",
      "\n",
      "Epoch 00664: loss did not improve from 0.00170\n",
      "Epoch 665/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.7395e-04 - vely_loss: 8.7821e-04\n",
      "\n",
      "Epoch 00665: loss did not improve from 0.00170\n",
      "Epoch 666/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.9073e-04 - vely_loss: 9.7996e-04\n",
      "\n",
      "Epoch 00666: loss did not improve from 0.00170\n",
      "Epoch 667/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0022 - velx_loss: 0.0011 - vely_loss: 0.0011\n",
      "\n",
      "Epoch 00667: loss did not improve from 0.00170\n",
      "Epoch 668/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9639e-04\n",
      "\n",
      "Epoch 00668: loss did not improve from 0.00170\n",
      "Epoch 669/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.5856e-04 - vely_loss: 9.4727e-04\n",
      "\n",
      "Epoch 00669: loss did not improve from 0.00170\n",
      "Epoch 670/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.7643e-04 - vely_loss: 8.7395e-04\n",
      "\n",
      "Epoch 00670: loss did not improve from 0.00170\n",
      "Epoch 671/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.8447e-04 - vely_loss: 8.8933e-04\n",
      "\n",
      "Epoch 00671: loss did not improve from 0.00170\n",
      "Epoch 672/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1316e-04 - vely_loss: 8.8988e-04\n",
      "\n",
      "Epoch 00672: loss did not improve from 0.00170\n",
      "Epoch 673/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 9.8963e-04 - vely_loss: 9.6585e-04\n",
      "\n",
      "Epoch 00673: loss did not improve from 0.00170\n",
      "Epoch 674/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.7240e-04 - vely_loss: 9.5203e-04\n",
      "\n",
      "Epoch 00674: loss did not improve from 0.00170\n",
      "Epoch 675/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9137e-04\n",
      "\n",
      "Epoch 00675: loss did not improve from 0.00170\n",
      "Epoch 676/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 8.7353e-04 - vely_loss: 8.7649e-04\n",
      "\n",
      "Epoch 00676: loss did not improve from 0.00170\n",
      "Epoch 677/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.8596e-04 - vely_loss: 8.9111e-04\n",
      "\n",
      "Epoch 00677: loss did not improve from 0.00170\n",
      "Epoch 678/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.7499e-04 - vely_loss: 8.7887e-04\n",
      "\n",
      "Epoch 00678: loss did not improve from 0.00170\n",
      "Epoch 679/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.8704e-04 - vely_loss: 8.8752e-04\n",
      "\n",
      "Epoch 00679: loss did not improve from 0.00170\n",
      "Epoch 680/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.4890e-04 - vely_loss: 9.4427e-04\n",
      "\n",
      "Epoch 00680: loss did not improve from 0.00170\n",
      "Epoch 681/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.6049e-04 - vely_loss: 9.5466e-04\n",
      "\n",
      "Epoch 00681: loss did not improve from 0.00170\n",
      "Epoch 682/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.9223e-04 - vely_loss: 8.9563e-04\n",
      "\n",
      "Epoch 00682: loss did not improve from 0.00170\n",
      "Epoch 683/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0017 - velx_loss: 8.5670e-04 - vely_loss: 8.5811e-04\n",
      "\n",
      "Epoch 00683: loss did not improve from 0.00170\n",
      "Epoch 684/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.1886e-04 - vely_loss: 9.1983e-04\n",
      "\n",
      "Epoch 00684: loss did not improve from 0.00170\n",
      "Epoch 685/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.0837e-04 - vely_loss: 9.1481e-04\n",
      "\n",
      "Epoch 00685: loss did not improve from 0.00170\n",
      "Epoch 686/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.2217e-04 - vely_loss: 9.2017e-04\n",
      "\n",
      "Epoch 00686: loss did not improve from 0.00170\n",
      "Epoch 687/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0018 - velx_loss: 8.8900e-04 - vely_loss: 8.9259e-04\n",
      "\n",
      "Epoch 00687: loss did not improve from 0.00170\n",
      "Epoch 688/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0018 - velx_loss: 9.3226e-04 - vely_loss: 9.0516e-04\n",
      "\n",
      "Epoch 00688: loss did not improve from 0.00170\n",
      "Epoch 689/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0019 - velx_loss: 9.4877e-04 - vely_loss: 9.4066e-04\n",
      "\n",
      "Epoch 00689: loss did not improve from 0.00170\n",
      "Epoch 690/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.1319e-04 - vely_loss: 9.2282e-04\n",
      "\n",
      "Epoch 00690: loss did not improve from 0.00170\n",
      "Epoch 691/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.2808e-04 - vely_loss: 9.2100e-04\n",
      "\n",
      "Epoch 00691: loss did not improve from 0.00170\n",
      "Epoch 692/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1198e-04 - vely_loss: 9.1222e-04\n",
      "\n",
      "Epoch 00692: loss did not improve from 0.00170\n",
      "Epoch 693/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.9804e-04 - vely_loss: 8.9480e-04\n",
      "\n",
      "Epoch 00693: loss did not improve from 0.00170\n",
      "Epoch 694/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.5650e-04 - vely_loss: 9.5837e-04\n",
      "\n",
      "Epoch 00694: loss did not improve from 0.00170\n",
      "Epoch 695/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.4041e-04 - vely_loss: 9.3432e-04\n",
      "\n",
      "Epoch 00695: loss did not improve from 0.00170\n",
      "Epoch 696/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.1685e-04 - vely_loss: 9.2278e-04\n",
      "\n",
      "Epoch 00696: loss did not improve from 0.00170\n",
      "Epoch 697/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1081e-04 - vely_loss: 9.0381e-04\n",
      "\n",
      "Epoch 00697: loss did not improve from 0.00170\n",
      "Epoch 698/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6684e-04 - vely_loss: 9.5769e-04\n",
      "\n",
      "Epoch 00698: loss did not improve from 0.00170\n",
      "Epoch 699/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.1111e-04 - vely_loss: 9.0419e-04\n",
      "\n",
      "Epoch 00699: loss did not improve from 0.00170\n",
      "Epoch 700/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6106e-04 - vely_loss: 9.4427e-04\n",
      "\n",
      "Epoch 00700: loss did not improve from 0.00170\n",
      "Epoch 701/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.0088e-04 - vely_loss: 8.9458e-04\n",
      "\n",
      "Epoch 00701: loss did not improve from 0.00170\n",
      "Epoch 702/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.6716e-04 - vely_loss: 8.6708e-04\n",
      "\n",
      "Epoch 00702: loss did not improve from 0.00170\n",
      "Epoch 703/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.7048e-04 - vely_loss: 9.4541e-04\n",
      "\n",
      "Epoch 00703: loss did not improve from 0.00170\n",
      "Epoch 704/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.2077e-04 - vely_loss: 9.0221e-04\n",
      "\n",
      "Epoch 00704: loss did not improve from 0.00170\n",
      "Epoch 705/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 0.0010\n",
      "\n",
      "Epoch 00705: loss did not improve from 0.00170\n",
      "Epoch 706/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.7002e-04\n",
      "\n",
      "Epoch 00706: loss did not improve from 0.00170\n",
      "Epoch 707/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6463e-04 - vely_loss: 8.6783e-04\n",
      "\n",
      "Epoch 00707: loss did not improve from 0.00170\n",
      "Epoch 708/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.5273e-04 - vely_loss: 8.4347e-04\n",
      "\n",
      "Epoch 00708: loss did not improve from 0.00170\n",
      "Epoch 709/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.3397e-04 - vely_loss: 8.1765e-04\n",
      "\n",
      "Epoch 00709: loss improved from 0.00170 to 0.00165, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 710/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.6758e-04 - vely_loss: 8.8007e-04\n",
      "\n",
      "Epoch 00710: loss did not improve from 0.00165\n",
      "Epoch 711/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6774e-04 - vely_loss: 8.7530e-04\n",
      "\n",
      "Epoch 00711: loss did not improve from 0.00165\n",
      "Epoch 712/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1877e-04 - vely_loss: 9.1221e-04\n",
      "\n",
      "Epoch 00712: loss did not improve from 0.00165\n",
      "Epoch 713/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.5416e-04 - vely_loss: 9.5209e-04\n",
      "\n",
      "Epoch 00713: loss did not improve from 0.00165\n",
      "Epoch 714/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0019 - velx_loss: 9.5160e-04 - vely_loss: 9.3742e-04\n",
      "\n",
      "Epoch 00714: loss did not improve from 0.00165\n",
      "Epoch 715/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.0105e-04 - vely_loss: 8.8171e-04\n",
      "\n",
      "Epoch 00715: loss did not improve from 0.00165\n",
      "Epoch 716/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6362e-04 - vely_loss: 9.3958e-04\n",
      "\n",
      "Epoch 00716: loss did not improve from 0.00165\n",
      "Epoch 717/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0019 - velx_loss: 9.3884e-04 - vely_loss: 9.3846e-04\n",
      "\n",
      "Epoch 00717: loss did not improve from 0.00165\n",
      "Epoch 718/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3364e-04 - vely_loss: 9.2503e-04\n",
      "\n",
      "Epoch 00718: loss did not improve from 0.00165\n",
      "Epoch 719/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.4148e-04 - vely_loss: 9.3262e-04\n",
      "\n",
      "Epoch 00719: loss did not improve from 0.00165\n",
      "Epoch 720/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.6867e-04 - vely_loss: 8.7441e-04\n",
      "\n",
      "Epoch 00720: loss did not improve from 0.00165\n",
      "Epoch 721/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0017 - velx_loss: 8.2496e-04 - vely_loss: 8.2722e-04\n",
      "\n",
      "Epoch 00721: loss did not improve from 0.00165\n",
      "Epoch 722/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.6540e-04 - vely_loss: 8.7079e-04\n",
      "\n",
      "Epoch 00722: loss did not improve from 0.00165\n",
      "Epoch 723/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.6601e-04 - vely_loss: 9.4539e-04\n",
      "\n",
      "Epoch 00723: loss did not improve from 0.00165\n",
      "Epoch 724/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 9.8475e-04 - vely_loss: 9.7074e-04\n",
      "\n",
      "Epoch 00724: loss did not improve from 0.00165\n",
      "Epoch 725/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.9777e-04 - vely_loss: 8.7937e-04\n",
      "\n",
      "Epoch 00725: loss did not improve from 0.00165\n",
      "Epoch 726/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.7759e-04 - vely_loss: 8.7617e-04\n",
      "\n",
      "Epoch 00726: loss did not improve from 0.00165\n",
      "Epoch 727/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.9195e-04\n",
      "\n",
      "Epoch 00727: loss did not improve from 0.00165\n",
      "Epoch 728/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.6504e-04 - vely_loss: 9.4250e-04\n",
      "\n",
      "Epoch 00728: loss did not improve from 0.00165\n",
      "Epoch 729/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 9.0562e-04 - vely_loss: 9.0131e-04\n",
      "\n",
      "Epoch 00729: loss did not improve from 0.00165\n",
      "Epoch 730/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.1243e-04 - vely_loss: 9.0789e-04\n",
      "\n",
      "Epoch 00730: loss did not improve from 0.00165\n",
      "Epoch 731/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.4933e-04 - vely_loss: 8.6200e-04\n",
      "\n",
      "Epoch 00731: loss did not improve from 0.00165\n",
      "Epoch 732/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.8663e-04 - vely_loss: 8.9469e-04\n",
      "\n",
      "Epoch 00732: loss did not improve from 0.00165\n",
      "Epoch 733/3000\n",
      "352/352 [==============================] - 86s 246ms/step - loss: 0.0017 - velx_loss: 8.5650e-04 - vely_loss: 8.5751e-04\n",
      "\n",
      "Epoch 00733: loss did not improve from 0.00165\n",
      "Epoch 734/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.0486e-04 - vely_loss: 8.9733e-04\n",
      "\n",
      "Epoch 00734: loss did not improve from 0.00165\n",
      "Epoch 735/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0019 - velx_loss: 9.8224e-04 - vely_loss: 9.6011e-04\n",
      "\n",
      "Epoch 00735: loss did not improve from 0.00165\n",
      "Epoch 736/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.2449e-04 - vely_loss: 9.2610e-04\n",
      "\n",
      "Epoch 00736: loss did not improve from 0.00165\n",
      "Epoch 737/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.5033e-04 - vely_loss: 8.7059e-04\n",
      "\n",
      "Epoch 00737: loss did not improve from 0.00165\n",
      "Epoch 738/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.4577e-04 - vely_loss: 8.5560e-04\n",
      "\n",
      "Epoch 00738: loss did not improve from 0.00165\n",
      "Epoch 739/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0018 - velx_loss: 8.8915e-04 - vely_loss: 8.9559e-04\n",
      "\n",
      "Epoch 00739: loss did not improve from 0.00165\n",
      "Epoch 740/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.5686e-04 - vely_loss: 9.4898e-04\n",
      "\n",
      "Epoch 00740: loss did not improve from 0.00165\n",
      "Epoch 741/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 9.1818e-04 - vely_loss: 9.0633e-04\n",
      "\n",
      "Epoch 00741: loss did not improve from 0.00165\n",
      "Epoch 742/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 8.8376e-04 - vely_loss: 8.7788e-04\n",
      "\n",
      "Epoch 00742: loss did not improve from 0.00165\n",
      "Epoch 743/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0018 - velx_loss: 9.2885e-04 - vely_loss: 9.1558e-04\n",
      "\n",
      "Epoch 00743: loss did not improve from 0.00165\n",
      "Epoch 744/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.4617e-04 - vely_loss: 9.3857e-04\n",
      "\n",
      "Epoch 00744: loss did not improve from 0.00165\n",
      "Epoch 745/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.3867e-04 - vely_loss: 9.1058e-04\n",
      "\n",
      "Epoch 00745: loss did not improve from 0.00165\n",
      "Epoch 746/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 8.9683e-04 - vely_loss: 8.8904e-04\n",
      "\n",
      "Epoch 00746: loss did not improve from 0.00165\n",
      "Epoch 747/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0017 - velx_loss: 8.6645e-04 - vely_loss: 8.7028e-04\n",
      "\n",
      "Epoch 00747: loss did not improve from 0.00165\n",
      "Epoch 748/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.7181e-04 - vely_loss: 8.7482e-04\n",
      "\n",
      "Epoch 00748: loss did not improve from 0.00165\n",
      "Epoch 749/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0018 - velx_loss: 9.0008e-04 - vely_loss: 8.9514e-04\n",
      "\n",
      "Epoch 00749: loss did not improve from 0.00165\n",
      "Epoch 750/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.1852e-04 - vely_loss: 9.1986e-04\n",
      "\n",
      "Epoch 00750: loss did not improve from 0.00165\n",
      "Epoch 751/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.6831e-04 - vely_loss: 9.4461e-04\n",
      "\n",
      "Epoch 00751: loss did not improve from 0.00165\n",
      "Epoch 752/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0019 - velx_loss: 9.3256e-04 - vely_loss: 9.2196e-04\n",
      "\n",
      "Epoch 00752: loss did not improve from 0.00165\n",
      "Epoch 753/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.7607e-04 - vely_loss: 8.6602e-04\n",
      "\n",
      "Epoch 00753: loss did not improve from 0.00165\n",
      "Epoch 754/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0017 - velx_loss: 8.5304e-04 - vely_loss: 8.5735e-04\n",
      "\n",
      "Epoch 00754: loss did not improve from 0.00165\n",
      "Epoch 755/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.0782e-04 - vely_loss: 8.8799e-04\n",
      "\n",
      "Epoch 00755: loss did not improve from 0.00165\n",
      "Epoch 756/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 9.1460e-04 - vely_loss: 8.9969e-04\n",
      "\n",
      "Epoch 00756: loss did not improve from 0.00165\n",
      "Epoch 757/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0018 - velx_loss: 9.0126e-04 - vely_loss: 8.7211e-04\n",
      "\n",
      "Epoch 00757: loss did not improve from 0.00165\n",
      "Epoch 758/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 9.0845e-04 - vely_loss: 9.1282e-04\n",
      "\n",
      "Epoch 00758: loss did not improve from 0.00165\n",
      "Epoch 759/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.7319e-04 - vely_loss: 8.7421e-04\n",
      "\n",
      "Epoch 00759: loss did not improve from 0.00165\n",
      "Epoch 760/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.2435e-04 - vely_loss: 8.4241e-04\n",
      "\n",
      "Epoch 00760: loss did not improve from 0.00165\n",
      "Epoch 761/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.0099e-04 - vely_loss: 8.8955e-04\n",
      "\n",
      "Epoch 00761: loss did not improve from 0.00165\n",
      "Epoch 762/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.1991e-04 - vely_loss: 9.0539e-04\n",
      "\n",
      "Epoch 00762: loss did not improve from 0.00165\n",
      "Epoch 763/3000\n",
      "352/352 [==============================] - 89s 251ms/step - loss: 0.0018 - velx_loss: 9.1289e-04 - vely_loss: 9.1323e-04\n",
      "\n",
      "Epoch 00763: loss did not improve from 0.00165\n",
      "Epoch 764/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.5055e-04 - vely_loss: 8.4077e-04\n",
      "\n",
      "Epoch 00764: loss did not improve from 0.00165\n",
      "Epoch 765/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.6599e-04 - vely_loss: 8.6988e-04\n",
      "\n",
      "Epoch 00765: loss did not improve from 0.00165\n",
      "Epoch 766/3000\n",
      "352/352 [==============================] - 87s 247ms/step - loss: 0.0018 - velx_loss: 8.9097e-04 - vely_loss: 8.7643e-04\n",
      "\n",
      "Epoch 00766: loss did not improve from 0.00165\n",
      "Epoch 767/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.9320e-04 - vely_loss: 8.9235e-04\n",
      "\n",
      "Epoch 00767: loss did not improve from 0.00165\n",
      "Epoch 768/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.3775e-04 - vely_loss: 9.2155e-04\n",
      "\n",
      "Epoch 00768: loss did not improve from 0.00165\n",
      "Epoch 769/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.4940e-04 - vely_loss: 8.5530e-04\n",
      "\n",
      "Epoch 00769: loss did not improve from 0.00165\n",
      "Epoch 770/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.1765e-04 - vely_loss: 9.1612e-04\n",
      "\n",
      "Epoch 00770: loss did not improve from 0.00165\n",
      "Epoch 771/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.0555e-04 - vely_loss: 9.0691e-04\n",
      "\n",
      "Epoch 00771: loss did not improve from 0.00165\n",
      "Epoch 772/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 8.9611e-04 - vely_loss: 8.8163e-04\n",
      "\n",
      "Epoch 00772: loss did not improve from 0.00165\n",
      "Epoch 773/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0020 - velx_loss: 0.0010 - vely_loss: 9.7794e-04\n",
      "\n",
      "Epoch 00773: loss did not improve from 0.00165\n",
      "Epoch 774/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.8394e-04 - vely_loss: 9.6282e-04\n",
      "\n",
      "Epoch 00774: loss did not improve from 0.00165\n",
      "Epoch 775/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.4194e-04 - vely_loss: 9.2566e-04\n",
      "\n",
      "Epoch 00775: loss did not improve from 0.00165\n",
      "Epoch 776/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.6044e-04 - vely_loss: 8.4851e-04\n",
      "\n",
      "Epoch 00776: loss did not improve from 0.00165\n",
      "Epoch 777/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0016 - velx_loss: 8.0916e-04 - vely_loss: 8.1650e-04\n",
      "\n",
      "Epoch 00777: loss improved from 0.00165 to 0.00163, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 778/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0016 - velx_loss: 7.9262e-04 - vely_loss: 8.0423e-04\n",
      "\n",
      "Epoch 00778: loss improved from 0.00163 to 0.00160, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 779/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0016 - velx_loss: 8.1270e-04 - vely_loss: 8.1805e-04\n",
      "\n",
      "Epoch 00779: loss did not improve from 0.00160\n",
      "Epoch 780/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6475e-04 - vely_loss: 8.7480e-04\n",
      "\n",
      "Epoch 00780: loss did not improve from 0.00160\n",
      "Epoch 781/3000\n",
      "352/352 [==============================] - 87s 249ms/step - loss: 0.0018 - velx_loss: 9.2423e-04 - vely_loss: 9.1425e-04\n",
      "\n",
      "Epoch 00781: loss did not improve from 0.00160\n",
      "Epoch 782/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.8606e-04 - vely_loss: 8.8244e-04\n",
      "\n",
      "Epoch 00782: loss did not improve from 0.00160\n",
      "Epoch 783/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.0434e-04 - vely_loss: 9.1100e-04\n",
      "\n",
      "Epoch 00783: loss did not improve from 0.00160\n",
      "Epoch 784/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.2628e-04 - vely_loss: 8.3057e-04\n",
      "\n",
      "Epoch 00784: loss did not improve from 0.00160\n",
      "Epoch 785/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0016 - velx_loss: 8.2120e-04 - vely_loss: 8.1505e-04\n",
      "\n",
      "Epoch 00785: loss did not improve from 0.00160\n",
      "Epoch 786/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.7658e-04 - vely_loss: 8.8285e-04\n",
      "\n",
      "Epoch 00786: loss did not improve from 0.00160\n",
      "Epoch 787/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 8.8751e-04 - vely_loss: 8.8341e-04\n",
      "\n",
      "Epoch 00787: loss did not improve from 0.00160\n",
      "Epoch 788/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 9.0023e-04 - vely_loss: 8.8777e-04\n",
      "\n",
      "Epoch 00788: loss did not improve from 0.00160\n",
      "Epoch 789/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.7652e-04 - vely_loss: 9.4617e-04\n",
      "\n",
      "Epoch 00789: loss did not improve from 0.00160\n",
      "Epoch 790/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.1791e-04 - vely_loss: 8.9993e-04\n",
      "\n",
      "Epoch 00790: loss did not improve from 0.00160\n",
      "Epoch 791/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.3253e-04 - vely_loss: 8.3265e-04\n",
      "\n",
      "Epoch 00791: loss did not improve from 0.00160\n",
      "Epoch 792/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0016 - velx_loss: 7.9086e-04 - vely_loss: 7.9334e-04\n",
      "\n",
      "Epoch 00792: loss improved from 0.00160 to 0.00158, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 793/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 8.0126e-04 - vely_loss: 7.9328e-04\n",
      "\n",
      "Epoch 00793: loss did not improve from 0.00158\n",
      "Epoch 794/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0018 - velx_loss: 8.9869e-04 - vely_loss: 9.0170e-04\n",
      "\n",
      "Epoch 00794: loss did not improve from 0.00158\n",
      "Epoch 795/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.9676e-04 - vely_loss: 9.0270e-04\n",
      "\n",
      "Epoch 00795: loss did not improve from 0.00158\n",
      "Epoch 796/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 8.9883e-04 - vely_loss: 8.8601e-04\n",
      "\n",
      "Epoch 00796: loss did not improve from 0.00158\n",
      "Epoch 797/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0019 - velx_loss: 9.3612e-04 - vely_loss: 9.1937e-04\n",
      "\n",
      "Epoch 00797: loss did not improve from 0.00158\n",
      "Epoch 798/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.1700e-04 - vely_loss: 9.1470e-04\n",
      "\n",
      "Epoch 00798: loss did not improve from 0.00158\n",
      "Epoch 799/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0018 - velx_loss: 8.8723e-04 - vely_loss: 8.7963e-04\n",
      "\n",
      "Epoch 00799: loss did not improve from 0.00158\n",
      "Epoch 800/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6973e-04 - vely_loss: 8.7365e-04\n",
      "\n",
      "Epoch 00800: loss did not improve from 0.00158\n",
      "Epoch 801/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.3146e-04 - vely_loss: 9.0046e-04\n",
      "\n",
      "Epoch 00801: loss did not improve from 0.00158\n",
      "Epoch 802/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.5374e-04 - vely_loss: 8.3395e-04\n",
      "\n",
      "Epoch 00802: loss did not improve from 0.00158\n",
      "Epoch 803/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.5365e-04 - vely_loss: 8.5188e-04\n",
      "\n",
      "Epoch 00803: loss did not improve from 0.00158\n",
      "Epoch 804/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.7860e-04 - vely_loss: 8.7369e-04\n",
      "\n",
      "Epoch 00804: loss did not improve from 0.00158\n",
      "Epoch 805/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0017 - velx_loss: 8.4317e-04 - vely_loss: 8.4007e-04\n",
      "\n",
      "Epoch 00805: loss did not improve from 0.00158\n",
      "Epoch 806/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0016 - velx_loss: 7.9731e-04 - vely_loss: 7.9883e-04\n",
      "\n",
      "Epoch 00806: loss did not improve from 0.00158\n",
      "Epoch 807/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6626e-04 - vely_loss: 8.4962e-04\n",
      "\n",
      "Epoch 00807: loss did not improve from 0.00158\n",
      "Epoch 808/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0019 - velx_loss: 9.6791e-04 - vely_loss: 9.4850e-04\n",
      "\n",
      "Epoch 00808: loss did not improve from 0.00158\n",
      "Epoch 809/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.4467e-04 - vely_loss: 9.2851e-04\n",
      "\n",
      "Epoch 00809: loss did not improve from 0.00158\n",
      "Epoch 810/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.7422e-04 - vely_loss: 8.6383e-04\n",
      "\n",
      "Epoch 00810: loss did not improve from 0.00158\n",
      "Epoch 811/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.7307e-04 - vely_loss: 8.6630e-04\n",
      "\n",
      "Epoch 00811: loss did not improve from 0.00158\n",
      "Epoch 812/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.6810e-04 - vely_loss: 8.4670e-04\n",
      "\n",
      "Epoch 00812: loss did not improve from 0.00158\n",
      "Epoch 813/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 8.2760e-04 - vely_loss: 8.1895e-04\n",
      "\n",
      "Epoch 00813: loss did not improve from 0.00158\n",
      "Epoch 814/3000\n",
      "352/352 [==============================] - 87s 248ms/step - loss: 0.0017 - velx_loss: 8.6604e-04 - vely_loss: 8.5943e-04\n",
      "\n",
      "Epoch 00814: loss did not improve from 0.00158\n",
      "Epoch 815/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.6067e-04 - vely_loss: 8.5361e-04\n",
      "\n",
      "Epoch 00815: loss did not improve from 0.00158\n",
      "Epoch 816/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0017 - velx_loss: 8.7582e-04 - vely_loss: 8.5347e-04\n",
      "\n",
      "Epoch 00816: loss did not improve from 0.00158\n",
      "Epoch 817/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0016 - velx_loss: 8.0498e-04 - vely_loss: 8.1300e-04\n",
      "\n",
      "Epoch 00817: loss did not improve from 0.00158\n",
      "Epoch 818/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.2574e-04 - vely_loss: 8.2840e-04\n",
      "\n",
      "Epoch 00818: loss did not improve from 0.00158\n",
      "Epoch 819/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.3286e-04 - vely_loss: 8.2987e-04\n",
      "\n",
      "Epoch 00819: loss did not improve from 0.00158\n",
      "Epoch 820/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 8.8876e-04 - vely_loss: 8.8991e-04\n",
      "\n",
      "Epoch 00820: loss did not improve from 0.00158\n",
      "Epoch 821/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0018 - velx_loss: 9.2054e-04 - vely_loss: 9.0170e-04\n",
      "\n",
      "Epoch 00821: loss did not improve from 0.00158\n",
      "Epoch 822/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.5085e-04 - vely_loss: 9.2314e-04\n",
      "\n",
      "Epoch 00822: loss did not improve from 0.00158\n",
      "Epoch 823/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 8.9033e-04 - vely_loss: 8.9364e-04\n",
      "\n",
      "Epoch 00823: loss did not improve from 0.00158\n",
      "Epoch 824/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0016 - velx_loss: 8.1315e-04 - vely_loss: 8.2540e-04\n",
      "\n",
      "Epoch 00824: loss did not improve from 0.00158\n",
      "Epoch 825/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 7.7994e-04 - vely_loss: 7.8423e-04\n",
      "\n",
      "Epoch 00825: loss improved from 0.00158 to 0.00156, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 826/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0016 - velx_loss: 8.2099e-04 - vely_loss: 8.2283e-04\n",
      "\n",
      "Epoch 00826: loss did not improve from 0.00156\n",
      "Epoch 827/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0016 - velx_loss: 8.2403e-04 - vely_loss: 8.2328e-04\n",
      "\n",
      "Epoch 00827: loss did not improve from 0.00156\n",
      "Epoch 828/3000\n",
      "352/352 [==============================] - 88s 251ms/step - loss: 0.0017 - velx_loss: 8.5775e-04 - vely_loss: 8.5182e-04\n",
      "\n",
      "Epoch 00828: loss did not improve from 0.00156\n",
      "Epoch 829/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0018 - velx_loss: 9.2931e-04 - vely_loss: 9.0982e-04\n",
      "\n",
      "Epoch 00829: loss did not improve from 0.00156\n",
      "Epoch 830/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0019 - velx_loss: 9.3886e-04 - vely_loss: 9.2460e-04\n",
      "\n",
      "Epoch 00830: loss did not improve from 0.00156\n",
      "Epoch 831/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.6261e-04 - vely_loss: 9.4738e-04\n",
      "\n",
      "Epoch 00831: loss did not improve from 0.00156\n",
      "Epoch 832/3000\n",
      "352/352 [==============================] - 88s 250ms/step - loss: 0.0018 - velx_loss: 9.0506e-04 - vely_loss: 8.8492e-04\n",
      "\n",
      "Epoch 00832: loss did not improve from 0.00156\n",
      "Epoch 833/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 8.1126e-04 - vely_loss: 8.1396e-04\n",
      "\n",
      "Epoch 00833: loss did not improve from 0.00156\n",
      "Epoch 834/3000\n",
      "352/352 [==============================] - 89s 254ms/step - loss: 0.0016 - velx_loss: 8.1243e-04 - vely_loss: 8.1265e-04\n",
      "\n",
      "Epoch 00834: loss did not improve from 0.00156\n",
      "Epoch 835/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 7.8453e-04 - vely_loss: 7.7911e-04\n",
      "\n",
      "Epoch 00835: loss improved from 0.00156 to 0.00156, saving model to Agrobot_First_TCN.hdf5\n",
      "Epoch 836/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0016 - velx_loss: 8.0635e-04 - vely_loss: 8.0482e-04\n",
      "\n",
      "Epoch 00836: loss did not improve from 0.00156\n",
      "Epoch 837/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0019 - velx_loss: 9.3290e-04 - vely_loss: 9.2723e-04\n",
      "\n",
      "Epoch 00837: loss did not improve from 0.00156\n",
      "Epoch 838/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.5360e-04 - vely_loss: 8.5463e-04\n",
      "\n",
      "Epoch 00838: loss did not improve from 0.00156\n",
      "Epoch 839/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 8.1518e-04 - vely_loss: 8.2488e-04\n",
      "\n",
      "Epoch 00839: loss did not improve from 0.00156\n",
      "Epoch 840/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.5513e-04 - vely_loss: 8.5062e-04\n",
      "\n",
      "Epoch 00840: loss did not improve from 0.00156\n",
      "Epoch 841/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.4849e-04 - vely_loss: 8.6785e-04\n",
      "\n",
      "Epoch 00841: loss did not improve from 0.00156\n",
      "Epoch 842/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.4941e-04 - vely_loss: 8.3484e-04\n",
      "\n",
      "Epoch 00842: loss did not improve from 0.00156\n",
      "Epoch 843/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0016 - velx_loss: 8.2429e-04 - vely_loss: 8.2433e-04\n",
      "\n",
      "Epoch 00843: loss did not improve from 0.00156\n",
      "Epoch 844/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.3704e-04 - vely_loss: 8.4471e-04\n",
      "\n",
      "Epoch 00844: loss did not improve from 0.00156\n",
      "Epoch 845/3000\n",
      "352/352 [==============================] - 88s 249ms/step - loss: 0.0017 - velx_loss: 8.4165e-04 - vely_loss: 8.4456e-04\n",
      "\n",
      "Epoch 00845: loss did not improve from 0.00156\n",
      "Epoch 846/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0016 - velx_loss: 8.2809e-04 - vely_loss: 8.1871e-04\n",
      "\n",
      "Epoch 00846: loss did not improve from 0.00156\n",
      "Epoch 847/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0017 - velx_loss: 8.7901e-04 - vely_loss: 8.6763e-04\n",
      "\n",
      "Epoch 00847: loss did not improve from 0.00156\n",
      "Epoch 848/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.4582e-04 - vely_loss: 8.5195e-04\n",
      "\n",
      "Epoch 00848: loss did not improve from 0.00156\n",
      "Epoch 849/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.2849e-04 - vely_loss: 8.3201e-04\n",
      "\n",
      "Epoch 00849: loss did not improve from 0.00156\n",
      "Epoch 850/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0018 - velx_loss: 9.3668e-04 - vely_loss: 9.0684e-04\n",
      "\n",
      "Epoch 00850: loss did not improve from 0.00156\n",
      "Epoch 851/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0017 - velx_loss: 8.7860e-04 - vely_loss: 8.6132e-04\n",
      "\n",
      "Epoch 00851: loss did not improve from 0.00156\n",
      "Epoch 852/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.6688e-04 - vely_loss: 8.6144e-04\n",
      "\n",
      "Epoch 00852: loss did not improve from 0.00156\n",
      "Epoch 853/3000\n",
      "352/352 [==============================] - 89s 252ms/step - loss: 0.0017 - velx_loss: 8.5865e-04 - vely_loss: 8.5286e-04\n",
      "\n",
      "Epoch 00853: loss did not improve from 0.00156\n",
      "Epoch 854/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0017 - velx_loss: 8.3646e-04 - vely_loss: 8.4445e-04\n",
      "\n",
      "Epoch 00854: loss did not improve from 0.00156\n",
      "Epoch 855/3000\n",
      "352/352 [==============================] - 89s 253ms/step - loss: 0.0017 - velx_loss: 8.2449e-04 - vely_loss: 8.3026e-04\n",
      "\n",
      "Epoch 00855: loss did not improve from 0.00156\n",
      "Epoch 856/3000\n",
      "352/352 [==============================] - 90s 255ms/step - loss: 0.0016 - velx_loss: 8.0472e-04 - vely_loss: 7.9074e-04\n",
      "\n",
      "Epoch 00856: loss did not improve from 0.00156\n",
      "Epoch 857/3000\n",
      "352/352 [==============================] - 93s 265ms/step - loss: 0.0017 - velx_loss: 8.7245e-04 - vely_loss: 8.5956e-04\n",
      "\n",
      "Epoch 00857: loss did not improve from 0.00156\n",
      "Epoch 858/3000\n",
      "114/352 [========>.....................] - ETA: 1:05 - loss: 0.0019 - velx_loss: 9.6569e-04 - vely_loss: 9.2164e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgrobot_First_TCN.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(model_name, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx_vel_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_vel_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m     \n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1178\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1179\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1180\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1181\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1182\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1183\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1185\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3021\u001b[0m   (graph_function,\n\u001b[1;32m   3022\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1956\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1959\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1962\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m     args,\n\u001b[1;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1965\u001b[0m     executing_eagerly)\n\u001b[1;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/nk_39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "model_name = 'Agrobot_First_TCN.hdf5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='loss', verbose=1, save_best_only=True)\n",
    "model.fit(x=X_train, y=[x_vel_train, y_vel_train],epochs=3000, shuffle=True,callbacks=[checkpoint],batch_size=batch_size)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e4cb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tamil-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Agrobot_First_TCN.hdf5'\n",
    "model = load_model(model_name,custom_objects={'TCN':TCN})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2faf51",
   "metadata": {},
   "source": [
    "Unseen Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agreed-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 11.597819785546104 1.8475261978411983 287.85761662195137 28.016093619359395\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 50.515676785565894 1.9532176482685595 233.75425011648193 21.70077385129724\n",
      "Median ATE and RTE 31.056748285555997 1.900371923054879\n",
      "Mean ATE and RTE 31.056748285555997 1.900371923054879\n",
      "STD ATE and RTE 19.458928500009897 0.05284572521368058\n"
     ]
    }
   ],
   "source": [
    "ATE = []\n",
    "RTE = []\n",
    "ATE_dist = []\n",
    "RTE_dist = []\n",
    "for i in range(len(size_of_each_test)):\n",
    "    Pvx, Pvy = model_pos_generator(X_test, size_of_each_test, \n",
    "                   x0_list_test, y0_list_test, window_size, stride,i,model)   \n",
    "    Gvx, Gvy = GT_pos_generator(x_vel_test,y_vel_test,size_of_each_test,\n",
    "                                x0_list_test, y0_list_test, window_size, stride,i)\n",
    "    \n",
    "    at, rt, at_all, rt_all = Cal_TE(Gvx, Gvy, Pvx, Pvy,\n",
    "                                    sampling_rate=100,window_size=window_size,stride=stride)\n",
    "    ATE.append(at)\n",
    "    RTE.append(rt)\n",
    "    ATE_dist.append(Cal_len_meters(Gvx, Gvy))\n",
    "    RTE_dist.append(Cal_len_meters(Gvx, Gvy, 600))\n",
    "    print('ATE, RTE, Trajectory Length, Trajectory Length (60 seconds)',ATE[i],RTE[i],ATE_dist[i],RTE_dist[i])\n",
    "    \n",
    "print('Median ATE and RTE', np.median(ATE),np.median(RTE))\n",
    "print('Mean ATE and RTE', np.mean(ATE),np.mean(RTE))\n",
    "print('STD ATE and RTE', np.std(ATE),np.std(RTE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0d983",
   "metadata": {},
   "source": [
    "Seen Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581dc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 9.929583229033165 0.41834522715670747 275.9200046693735 26.05521985043159\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 10.57364107621656 0.45888140362517477 288.5516252739624 26.686326997524706\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 9.324512226161305 0.29680974620574174 277.4080562340305 25.52302140411892\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 12.45141606422189 0.5017511070346212 282.1387445022608 26.470438993107596\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 10.089872299508146 0.398348353084502 312.2789515155521 27.732995954310113\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 13.146590139279336 0.5347597787876246 279.07174829470057 25.347916855981047\n",
      "ATE, RTE, Trajectory Length, Trajectory Length (60 seconds) 27.248910656643634 0.6988171342476724 264.3363282021496 23.241357047594228\n",
      "Median ATE and RTE 10.57364107621656 0.45888140362517477\n",
      "Mean ATE and RTE 13.252075098723433 0.47253039287743487\n",
      "STD ATE and RTE 5.857861936870226 0.1167629367032226\n"
     ]
    }
   ],
   "source": [
    "ATE = []\n",
    "RTE = []\n",
    "ATE_dist = []\n",
    "RTE_dist = []\n",
    "for i in range(len(size_of_each_train)):\n",
    "    Pvx, Pvy = model_pos_generator(X_train, size_of_each_train, \n",
    "                   x0_list_train, y0_list_train, window_size, stride,i,model)   \n",
    "    Gvx, Gvy = GT_pos_generator(x_vel_train,y_vel_train,size_of_each_train,\n",
    "                                x0_list_train, y0_list_train, window_size, stride,i)\n",
    "    \n",
    "    at, rt, at_all, rt_all = Cal_TE(Gvx, Gvy, Pvx, Pvy,\n",
    "                                    sampling_rate=100,window_size=window_size,stride=stride)\n",
    "    ATE.append(at)\n",
    "    RTE.append(rt)\n",
    "    ATE_dist.append(Cal_len_meters(Gvx, Gvy))\n",
    "    RTE_dist.append(Cal_len_meters(Gvx, Gvy, 600))\n",
    "    print('ATE, RTE, Trajectory Length, Trajectory Length (60 seconds)',ATE[i],RTE[i],ATE_dist[i],RTE_dist[i])\n",
    "    \n",
    "print('Median ATE and RTE', np.median(ATE),np.median(RTE))\n",
    "print('Mean ATE and RTE', np.mean(ATE),np.mean(RTE))\n",
    "print('STD ATE and RTE', np.std(ATE),np.std(RTE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9647c5d",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42514d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pvx, Pvy = model_pos_generator(X_train, size_of_each_train, \n",
    "               x0_list_train, y0_list_train, window_size, stride,0,model)   \n",
    "Gvx, Gvy = GT_pos_generator(x_vel_train,y_vel_train,size_of_each_train,\n",
    "                            x0_list_train, y0_list_train, window_size, stride,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ed2380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa370131130>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Gvx[0:2000],Gvy[0:2000])\n",
    "plt.plot(Pvx[0:2000],Pvy[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7174b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.05510247694568\n"
     ]
    }
   ],
   "source": [
    "print(Cal_len_meters(Gvx[0:2250],Gvy[0:2250]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
